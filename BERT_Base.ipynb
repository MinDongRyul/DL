{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7814163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchsummary as ts\n",
    "import torchinfo as ti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8043",
   "metadata": {},
   "source": [
    "# BERT 구현\n",
    "### 학습 목표\n",
    "1. BERT의 Embeddings모듈 동작을 이해하고 구현할 수 있다.\n",
    "2. BERT의 Self-Attention을 활용한 Transformer 부분인 BertLayer모듈의 동작을 이해하고 구현할 수 있다.\n",
    "3. BERT의 Pooler모듈의 동작을 이해하고 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff8569",
   "metadata": {},
   "source": [
    "## 8.2.2 BERT_Base의 네트워크 설정 파일 읽기\n",
    "- 먼저 BERT_Base에서 Transformer가 12단인 것과 특징량 벡터가 768차원인 것 등을 적은 weights폴더의 네트워크 설정 파일 bert_config.json을 읽어들입니다.\n",
    "- 읽어들인 JSON파일의 사전형 변수에서 key 'hidden'값을 취하려면 config['hidden_size']로 적어야합니다. 이를 config.hidden_size로 기술하면 깔끔합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0ec71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architectures': ['BertForMaskedLM'],\n",
       " 'attention_probs_dropout_prob': 0.1,\n",
       " 'gradient_checkpointing': False,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'max_position_embeddings': 512,\n",
       " 'model_type': 'bert',\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'pad_token_id': 0,\n",
       " 'position_embedding_type': 'absolute',\n",
       " 'transformers_version': '4.6.0.dev0',\n",
       " 'type_vocab_size': 2,\n",
       " 'use_cache': True,\n",
       " 'vocab_size': 30522}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config.json에서 설정을 읽어들여 JSON 사전 변수를 오브젝트 변수로 변환\n",
    "import json\n",
    "\n",
    "config_file = './weights/bert_config.json'\n",
    "\n",
    "# 파일을 열어 JSON으로 읽는다.\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbb4a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전 변수를 오브젝트 변수로\n",
    "from attrdict import AttrDict\n",
    "\n",
    "config = AttrDict(config)\n",
    "config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69339f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063c1c",
   "metadata": {},
   "source": [
    "## 8.2.3 BERT에 레이어 정규화 층 정의\n",
    "- BERT 모델 구축의 사전 준비로 레이어 정규화 층의 클래스를 정의합니다. 7장에서 사용한 것 처럼 파이토치에도 레이어 정규화가 있습니다.\n",
    "- 텐서플로와 파이토치에서는 레이어 정규화의 구현 방법이 약간 다릅니다. 텐서의 마지막 채널(즉 단어의 특징량 벡터 768차원)에 평균 0, 표준편차 1이 되도록 레이어 정규화를 수행합니다. 0으로 나누지 않도록 보조 항 엡실론을 넣는 방법은 파이토치와 텐서플로가 서로 다릅니다.\n",
    "- 이번에 사용할 학습된 모델은 구글이 공개한 텐서플로의 학습 결과에 기반하여 텐서플로 버전의 레이어 정규화 층을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b22ec377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT용으로 레이어 정규화 층 정의\n",
    "# 세부 구현을 텐서플로에 맞춘다.\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class BertLayerNorm(nn.Module):\n",
    "    '''레이어 정규화 층'''\n",
    "    \n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        super(BertLayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_size)) # weight에 대한 것\n",
    "        self.beta = nn.Parameter(torch.zeros(hidden_size)) # 바이어스에 대한 것\n",
    "        self.variance_epsilon = eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 평균\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        # 분산\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        # 일반 정규화 적용 variance_epsilon은 0으로 나누지 않도록 보조 항 삽입\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        # 최종적으로 gamma 와 x를 곱하고 beta를 더해서 return\n",
    "        return self.gamma * x + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c60cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BertLayerNorm                            1,536\n",
       "=================================================================\n",
       "Total params: 1,536\n",
       "Trainable params: 1,536\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "ti.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba8227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts.summary(model, input_size=(10, 768))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13acf22d",
   "metadata": {},
   "source": [
    "## 8.2.4 Embedding 구현\n",
    "### Transformer의 Embeddings 모듈과 두 가지 큰 차이점 존재\n",
    "- 첫째, Positional Embedding(위치 정보를 벡터로 변환)의 표현 기법을 Transformer는 sin, cos으로 계산하지만 BERT는 표현 방법도 학습시킵니다. 학습 시키는 것은 단어의 위치 정보뿐이며 단어 벡터의 차원 정보는 부여하지 않습니다. 즉 첫 번째 단어의 768차원은 동일한 position_embeddings값이 저장 되고 두 번째 단어는 첫 번째 단어와는 다르지만 768차원 방향에 같은 position_embeddings값이 저장됩니다.\n",
    "- 둘째, Sentence Embedding의 존재입니다. BERT는 두 문장을 입력합니다. 첫 번째 문장과 두 번째 문장을 구분하기 위한 Embedding를 준비합니다. Embeddings 모듈에서는 Token Embedding, Positional Embedding, Sentence Embedding에서 각각 구할 세 개의 텐서를 Transformer처럼 더하여 Embeddings 모듈의 출력으로 합니다. Embeddings모듈에 대한 입력 텐서는 (batch_size, seq_len)크기로 이루어진 문장의 단어 ID 나열인 변수 input_ids와 (batch_size, seq_len)의 각 단어가 첫 번째 문장인지 두 번째 문장인지 나타내는 문장 id인 변수 token_type_ids가 됩니다. 출력은 (batch_size, seq_len, hidden_size)의 텐서입니다. seq_len은 512이고 hidden_size는 768입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1c4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 Embeddings 모듈\n",
    "class BertEmbeddings(nn.Module):\n",
    "    '''문장의 단어 ID열과 첫 번째인지 두 번째 문장인지 정보를 내장 벡터로 변환'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        \n",
    "        # 세 개의 벡터 표현 내장\n",
    "        \n",
    "        # Token Embedding: 단어 ID를 단어 벡터로 변환\n",
    "        # vocab_size = 30522로 BERT의 학습된 모델에 사용된 vocabulary 양\n",
    "        # hidden_size = 768로 특징량 벡터의 길이는 768\n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        \n",
    "        # padding_idx = 0의 idx = 0 단어 벡터는 0으로 한다. BERT의 vocabulary의 idx=0은 [PAD]이다\n",
    "        \n",
    "        # Transformer Positional Embedding: 위치 정보 텐서를 벡터로 변환\n",
    "        # Transformer의 경우는 sin, cos로 이루어진 고정 값이지만 BERT는 학습시킨다.\n",
    "        # max_position_embeddings = 512로 문장 길이는 512단어\n",
    "        self.position_embeddings = nn.Embedding(\n",
    "            config.max_position_embeddings, config.hidden_size)\n",
    "        \n",
    "        # Sentence Embedding: 첫 번째, 두 번째 문장을 벡터로 변환\n",
    "        # type_vocab_size = 2\n",
    "        self.token_type_embeddings = nn.Embedding(\n",
    "            config.type_vocab_size, config.hidden_size)\n",
    "        \n",
    "        # 작성한 레이어 정규화 층\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        \n",
    "        # 드롭아웃 'hidden_dropout_prob':0.1\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        '''\n",
    "        input_ids: [batch_size, seq_len] 문장의 단어 ID 나열\n",
    "        token_type_ids: [batch_size, seq_len] 각 단어가 첫 번째 문장인지 두 번째 문장인지 나타내는 id\n",
    "        '''\n",
    "        \n",
    "        # 1. Token Embeddings\n",
    "        # 단어 ID를 단어 벡터로 변환\n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        \n",
    "        # 2. Sentence Embeddings\n",
    "        # token_type_ids가 없는 경우는 문장의 모든 단어를 첫 번째 문장으로 하여 0으로 설정\n",
    "        # input_ids와 같은 크기로 제로 텐서 작성\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        \n",
    "        # 3. Transformer Positional Embedding:\n",
    "        # [0, 1, 2, ...]로 문장의 길이 만큼 숫자가 하나씩 올라간다.\n",
    "        # [batch_size, seq_len]의 텐서 positional_ids 작성\n",
    "        # positional_ids를 입력하여 position_embeddings 층에서 768차원의 텐서를 꺼낸다\n",
    "        seq_length = input_ids.size(1) # 문장 길이\n",
    "        position_ids = torch.arange(\n",
    "            seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        \n",
    "        # 세 개의 내장 텐서를 더한다. [batch_size, seq_len, hidden_size]\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        \n",
    "        # 레이어 정규화와 드롭아웃 실행\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d25b756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BertEmbeddings                           --\n",
       "├─Embedding: 1-1                         23,440,896\n",
       "├─Embedding: 1-2                         393,216\n",
       "├─Embedding: 1-3                         1,536\n",
       "├─BertLayerNorm: 1-4                     1,536\n",
       "├─Dropout: 1-5                           --\n",
       "=================================================================\n",
       "Total params: 23,837,184\n",
       "Trainable params: 23,837,184\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertEmbeddings(config)\n",
    "ti.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8414b080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c503029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
    "token_type_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59e17bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5864,  0.7621,  0.0181,  ..., -1.5074,  1.7349,  0.7103],\n",
       "         [ 0.3085,  0.9922,  0.5774,  ..., -3.0212,  2.4898, -0.7666],\n",
       "         [ 0.0000,  0.2328,  0.0461,  ...,  0.0000,  1.9305,  2.1867],\n",
       "         [ 0.0000, -0.0000,  1.3760,  ..., -0.2753,  0.0000,  1.4326],\n",
       "         [ 0.6090, -0.5061,  1.1534,  ..., -0.5636,  2.5507,  0.1521]],\n",
       "\n",
       "        [[ 0.4883,  0.3363,  0.5141,  ..., -1.7378,  0.0000,  2.2326],\n",
       "         [ 0.2567, -0.1650, -0.1615,  ..., -0.0000,  2.5798, -0.1563],\n",
       "         [ 0.1157,  1.1629,  0.0148,  ...,  0.7537,  1.2637,  3.1691],\n",
       "         [-0.5881,  0.3833,  1.7950,  ..., -0.2181,  2.2109,  2.3572],\n",
       "         [ 0.8521, -0.0000,  0.7996,  ..., -1.5744,  3.0043, -0.0262]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25401d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4806e+00,  1.1494e+00, -5.8721e-01,  3.4110e-01, -9.6616e-01,\n",
       "        -6.8044e-01,  1.4798e+00,  1.0209e+00, -6.4485e-01,  4.5467e-01,\n",
       "         9.7513e-01, -2.6011e-01, -5.5265e-01,  8.2508e-01, -1.4231e+00,\n",
       "         4.4060e-01,  6.4321e-02, -8.1924e-01,  5.5717e-01,  1.4058e+00,\n",
       "        -1.2668e-01,  1.2402e+00, -1.9757e+00, -2.4879e-01, -1.8383e+00,\n",
       "         4.5399e-01,  7.0577e-01,  4.1375e-01, -3.5001e-01,  9.1271e-01,\n",
       "        -2.8519e+00, -1.9229e-01,  4.1333e-01,  3.0596e+00,  5.8749e-01,\n",
       "         1.4367e+00,  2.8893e-01,  1.4455e+00, -6.1530e-01,  8.0917e-01,\n",
       "        -1.2648e+00, -8.2938e-01, -2.7060e-01, -2.1032e-01, -8.6232e-01,\n",
       "         2.0441e+00, -1.2790e+00, -4.3685e-01,  1.1931e+00, -2.1604e+00,\n",
       "        -3.9213e-01,  1.1190e+00,  4.5902e-01,  4.0149e-01, -1.6754e+00,\n",
       "         1.4853e+00, -8.6224e-01,  7.9496e-01, -2.5201e-01,  9.5908e-01,\n",
       "        -1.1209e+00, -7.3761e-01, -1.3217e+00, -5.9904e-01,  6.4476e-01,\n",
       "         2.8471e-01,  1.3390e-01,  3.5054e-01,  5.6230e-01, -4.8615e-01,\n",
       "        -3.1118e-01,  9.2990e-01,  5.7935e-01,  2.2233e-01,  1.4344e+00,\n",
       "         4.5663e-01, -1.9595e+00, -1.1534e+00,  1.2830e+00,  9.4876e-01,\n",
       "        -1.3708e-02,  1.3371e+00, -2.6717e-01,  1.0768e+00,  1.3290e+00,\n",
       "        -9.4531e-01, -8.7393e-01, -9.2177e-02, -1.6729e+00, -2.0135e-01,\n",
       "         1.3144e-01, -4.9637e-01,  3.9113e-01, -8.9447e-01, -8.0635e-01,\n",
       "        -1.9653e+00,  1.2900e-01, -6.0268e-01, -8.9576e-01, -4.0272e-01,\n",
       "        -6.7903e-02, -1.1453e+00,  8.7858e-01, -6.6927e-01, -1.7156e+00,\n",
       "        -2.7316e-02, -6.5925e-02,  1.5464e+00, -1.1190e+00,  1.1412e+00,\n",
       "         8.8340e-01, -8.3873e-01,  1.5097e+00,  2.6331e-01,  2.2619e+00,\n",
       "         5.5359e-01,  1.1428e+00,  1.9601e+00,  5.8904e-02,  8.0502e-01,\n",
       "         7.2016e-01, -1.7844e+00,  1.0982e+00, -1.5447e+00, -4.6131e-01,\n",
       "        -8.6752e-01, -1.8079e+00,  1.7214e+00, -5.3701e-01, -9.5359e-01,\n",
       "        -8.6679e-01, -4.7535e-01, -5.3189e-02,  1.3112e+00, -1.6037e+00,\n",
       "        -7.3133e-01, -6.8802e-01,  5.6345e-01,  1.5042e+00, -4.6064e-01,\n",
       "         1.7296e+00,  9.6755e-01,  5.4238e-01,  1.5271e+00, -3.9871e-01,\n",
       "        -1.3411e+00,  1.1894e+00,  1.9720e-01,  7.2624e-01,  1.5924e+00,\n",
       "         4.2513e-01, -6.6320e-01,  6.2654e-01,  6.4669e-01, -3.6786e+00,\n",
       "        -3.6719e-01, -9.2850e-01, -5.3840e-01, -5.4363e-03, -2.6112e+00,\n",
       "        -7.4516e-01, -5.2917e-01,  3.6458e-01, -7.1159e-01, -9.8547e-02,\n",
       "         2.9188e-01,  1.5106e+00, -6.9753e-01, -9.0084e-01, -6.5161e-02,\n",
       "         1.5161e-01,  1.7725e+00, -3.0930e-01,  2.0916e-01, -7.3747e-01,\n",
       "         1.8570e+00,  3.7338e-01,  3.1041e-01,  9.1891e-02, -1.0607e+00,\n",
       "         1.3635e+00,  1.0482e-01, -4.4561e-01, -1.2257e+00, -2.1716e-02,\n",
       "        -2.5923e-01,  2.2917e-01,  1.1660e+00, -1.6268e+00,  2.9900e-01,\n",
       "         3.6142e-01,  2.0208e+00, -8.5239e-01,  1.2435e+00,  8.9065e-01,\n",
       "        -5.4252e-01, -3.4534e-01,  6.5524e-01,  8.6506e-01, -7.8777e-01,\n",
       "         2.8030e-01, -6.2822e-01,  1.0311e+00,  7.4808e-01, -8.4824e-01,\n",
       "         6.2454e-01, -2.3669e-01,  1.3441e+00,  1.5451e+00,  6.1847e-01,\n",
       "         2.0130e-02, -1.5932e-01, -6.5844e-02,  1.0807e+00,  4.6751e-01,\n",
       "        -1.2978e+00, -8.9142e-01,  1.3170e+00, -1.6631e-01,  1.3730e+00,\n",
       "         4.2081e-01,  1.0181e+00, -9.4213e-01,  1.1352e+00,  4.1957e-01,\n",
       "         1.5855e+00,  9.1275e-02, -3.6226e-01,  3.3849e-01,  6.4666e-01,\n",
       "         3.5273e-01, -4.5058e-01,  6.6296e-01,  4.7491e-02,  3.2377e-01,\n",
       "        -8.5350e-01,  9.8457e-01,  2.8384e-01, -2.1577e-01, -1.2720e+00,\n",
       "         2.1114e-01,  1.2666e-01,  1.3388e+00,  1.2089e+00, -5.2565e-01,\n",
       "        -4.1388e-01,  7.4632e-01, -9.0741e-01, -2.6017e-01, -2.0908e+00,\n",
       "        -9.9265e-01, -3.4775e-02,  2.3580e-01, -7.8616e-01, -7.9570e-01,\n",
       "         6.9609e-01,  4.6822e-01, -1.3527e+00, -2.4007e-01, -6.8607e-02,\n",
       "        -1.6815e+00, -1.3314e+00, -2.9002e-01, -1.1898e+00, -7.8971e-01,\n",
       "         1.1903e+00, -1.6616e+00, -3.9933e-01,  2.0640e+00, -4.1961e-01,\n",
       "        -1.2068e+00,  1.1924e+00, -1.2841e-01, -1.0397e+00, -2.6552e+00,\n",
       "        -3.0464e-01,  4.7696e-01,  9.2623e-01,  9.4342e-01,  1.9541e+00,\n",
       "        -1.5548e-01,  4.6739e-01, -9.1994e-01,  9.1252e-01,  1.3151e+00,\n",
       "        -1.7422e-01,  3.2951e-01,  6.8583e-01,  3.4387e-01,  1.3365e-01,\n",
       "         1.5275e+00, -8.0921e-01, -6.3767e-01, -9.6998e-01,  7.7459e-02,\n",
       "        -5.6349e-01, -3.5400e-01, -3.3130e-01, -1.0143e-01,  2.2533e-01,\n",
       "        -1.4214e+00, -9.5169e-01, -1.4479e+00,  5.1408e-01,  2.0303e-01,\n",
       "         1.3865e+00, -3.3901e-02, -1.3362e+00,  5.5733e-01,  6.7237e-01,\n",
       "         2.5105e+00,  7.1927e-02,  6.1087e-01, -1.8296e+00,  4.0894e-01,\n",
       "         2.0382e-01,  5.5677e-01,  2.5820e+00, -3.7894e-01,  2.3342e+00,\n",
       "        -8.0207e-01, -6.5994e-01, -8.5212e-02,  3.8427e-01,  2.0897e+00,\n",
       "        -1.3515e+00,  3.8728e-02,  8.4032e-02, -9.9028e-01,  9.0995e-01,\n",
       "         7.2564e-01, -6.2936e-01, -4.3469e-01,  1.1881e+00, -1.0438e+00,\n",
       "         6.4239e-01,  1.1400e-01,  4.8259e-01,  6.3165e-01, -2.2215e-01,\n",
       "        -1.5170e+00, -6.9187e-01, -1.0643e+00, -6.7932e-01, -1.9437e+00,\n",
       "         1.2207e+00, -1.6049e-01,  7.1282e-01,  6.4900e-01,  2.9452e-01,\n",
       "         8.9943e-01, -9.7410e-01, -1.0591e-01, -1.8094e-01,  2.0732e-01,\n",
       "        -1.3337e+00,  8.7626e-01,  7.4710e-01, -9.3808e-01,  4.0059e-01,\n",
       "         1.2590e+00,  1.3096e-01, -3.4083e-01, -3.1034e-01,  5.5533e-03,\n",
       "         1.2811e+00,  8.0833e-01,  1.8739e+00,  1.5303e+00, -9.6257e-02,\n",
       "         8.4393e-02, -2.9808e-01, -1.0107e+00, -7.8493e-02,  7.5831e-01,\n",
       "        -4.3388e-01, -1.0062e+00, -3.6825e-01,  1.3842e+00,  3.0491e-01,\n",
       "         1.6549e+00, -1.0629e+00,  5.5171e-02,  3.4689e-01,  1.4238e+00,\n",
       "         1.0857e+00, -1.0102e+00,  4.7217e-01,  1.3977e+00, -2.2216e+00,\n",
       "        -3.5334e-01,  8.1660e-01, -8.3455e-01, -1.0060e+00, -2.8984e-01,\n",
       "         1.5708e+00, -3.9586e-01,  8.6622e-01, -8.7278e-01,  1.3238e+00,\n",
       "        -6.9462e-01,  2.8858e-01,  1.0229e-03,  1.8800e+00,  2.1919e+00,\n",
       "        -6.8833e-01,  5.8012e-01,  1.9045e+00, -2.4699e+00, -1.3532e-01,\n",
       "        -6.5404e-01, -1.0923e+00,  8.0679e-01,  2.2737e-01, -6.6157e-01,\n",
       "        -1.4445e+00,  1.3440e+00, -1.6606e-01,  1.1486e+00,  7.0918e-01,\n",
       "         6.2331e-01, -2.7409e+00,  1.6238e-01,  6.5742e-01,  2.0533e-01,\n",
       "         6.8189e-01, -1.4750e+00, -3.7774e-01,  4.4645e-01, -2.8724e-01,\n",
       "         7.8269e-01, -4.2502e-01,  1.2002e+00, -1.3806e+00,  1.2631e+00,\n",
       "         2.7702e-01,  2.2034e+00, -1.4554e+00,  8.3099e-01, -6.1134e-01,\n",
       "         5.3167e-01, -1.9271e+00,  7.7040e-01,  1.1284e-01, -8.3661e-01,\n",
       "        -1.9810e+00,  9.9106e-01, -1.4497e+00,  8.8939e-01,  1.9171e-01,\n",
       "         7.8512e-01, -1.0113e+00, -2.3621e-01,  2.1686e+00,  1.4079e+00,\n",
       "        -1.8035e+00, -1.1305e-01, -5.0796e-01, -7.3925e-02, -8.3601e-02,\n",
       "        -3.1519e-01, -6.9396e-01, -8.7792e-01,  6.3875e-01, -9.5480e-01,\n",
       "         6.1161e-01, -4.7895e-01, -3.0301e-02, -6.3752e-01, -3.3432e-01,\n",
       "         8.1934e-01,  1.8677e+00,  1.1208e+00, -1.2953e-01, -5.8138e-03,\n",
       "         4.3673e-01, -1.0646e+00, -7.2428e-01, -2.6414e-01, -7.3028e-01,\n",
       "        -5.5292e-04,  5.9216e-02, -1.2919e+00,  1.4239e+00, -6.3704e-01,\n",
       "         5.8581e-01, -2.2942e-01,  2.4246e-01,  9.1875e-01, -9.0467e-01,\n",
       "        -8.7748e-03, -2.9230e-01, -6.7927e-01, -1.0429e+00,  7.9479e-01,\n",
       "        -1.3920e+00, -9.5178e-01,  1.8612e+00, -1.1673e+00,  4.1003e-01,\n",
       "         1.3643e+00,  1.0532e+00,  7.8576e-02,  1.3271e+00,  1.0343e+00,\n",
       "         6.2484e-01, -7.2278e-01,  1.7685e+00,  1.8828e+00,  1.6424e+00,\n",
       "        -6.2228e-01, -2.2081e-01,  2.4602e-01,  2.9991e-01,  4.4085e-01,\n",
       "        -5.3887e-01,  1.0393e+00, -7.2065e-02,  1.8600e+00, -4.6261e-01,\n",
       "         7.2387e-02, -7.9669e-01,  1.6485e+00,  8.4639e-01,  5.8363e-01,\n",
       "         9.4985e-02, -4.8394e-01,  2.0662e-02,  4.2622e-01,  3.6928e-01,\n",
       "        -1.6259e-01, -2.2536e-01, -2.1832e-01,  9.4435e-01,  2.9645e-01,\n",
       "         6.4694e-01,  8.2726e-01, -1.2384e-01,  9.7578e-01, -1.5389e+00,\n",
       "        -2.6448e-01,  7.6053e-01,  1.0182e+00, -4.9530e-01, -2.9890e-01,\n",
       "        -1.4383e+00, -8.7091e-01, -4.8038e-01, -9.8328e-01, -2.1150e-01,\n",
       "        -1.6727e-01,  4.9033e-01,  4.6857e-01,  1.3823e+00, -8.7035e-01,\n",
       "         6.6058e-02,  5.4142e-01,  8.2594e-01, -3.7667e-01,  7.4486e-01,\n",
       "        -5.2552e-01,  4.4376e-01,  6.8982e-01, -5.4374e-01, -5.5373e-01,\n",
       "         2.3212e-01, -9.9483e-01,  1.8813e+00, -8.4925e-02, -1.4986e+00,\n",
       "         3.6889e-02, -9.5666e-01,  4.0709e-01,  1.0792e+00, -1.0584e+00,\n",
       "         5.0961e-02, -4.8019e-01, -1.6209e+00, -3.3559e-01, -1.0538e+00,\n",
       "         8.0755e-01, -4.4271e-02,  4.6017e-01, -7.1007e-01,  1.7470e+00,\n",
       "        -1.1710e-01, -1.2056e+00, -7.7926e-01,  3.9268e-01,  5.2909e-01,\n",
       "         5.9890e-01,  2.6364e-01,  4.6716e-01, -4.7520e-01,  1.1435e+00,\n",
       "         1.6602e-01,  6.3273e-02,  1.2267e+00,  4.1416e-02, -8.3262e-01,\n",
       "        -4.5457e-01, -6.0224e-01,  1.0620e+00, -1.2958e+00,  1.6321e+00,\n",
       "        -7.7012e-01,  1.0906e+00, -1.3219e+00, -5.3683e-02,  3.7440e-01,\n",
       "         8.4781e-01, -3.9903e-01,  9.7048e-02,  1.4825e+00, -2.0773e-02,\n",
       "        -2.5898e-01,  1.5640e+00,  5.3352e-01, -5.6498e-01, -1.8413e+00,\n",
       "        -6.1724e-01,  3.6053e-01,  3.1030e-02,  9.1261e-01, -1.0752e-01,\n",
       "        -4.7174e-01,  8.5526e-01, -1.6942e+00, -2.2468e-01, -7.3252e-01,\n",
       "        -2.4369e-02,  2.5152e+00,  2.0314e-01,  1.8607e-01, -9.8657e-02,\n",
       "        -1.4285e+00, -1.3111e+00, -1.7763e-01, -4.8207e-01,  1.9608e-01,\n",
       "        -3.8767e-01, -1.9659e-01,  4.3509e-01, -4.7211e-01,  1.5172e+00,\n",
       "         1.2640e+00, -4.7858e-01, -1.0568e+00, -2.1205e+00,  1.5038e+00,\n",
       "         8.5351e-01,  1.5540e+00,  3.3679e-01,  3.2608e-01, -8.2012e-01,\n",
       "        -2.2381e-01,  7.0846e-01,  7.7961e-02, -3.2011e-02,  5.7434e-01,\n",
       "         1.6161e-01,  5.6816e-01, -3.4197e-01,  7.2320e-01, -3.4196e-01,\n",
       "         4.7898e-01, -7.4160e-01, -1.2542e+00, -3.6028e-01,  2.0627e+00,\n",
       "        -4.2340e-01, -7.5879e-01, -1.2850e+00,  8.4815e-01,  6.1592e-02,\n",
       "        -1.1300e+00,  5.5199e-01, -1.6606e+00, -9.5834e-01, -1.3933e+00,\n",
       "         1.6411e+00,  1.8321e+00,  1.8565e+00, -9.7623e-01, -1.3251e+00,\n",
       "        -3.1267e-01, -1.1773e+00, -7.7704e-01,  5.7305e-01, -9.2236e-01,\n",
       "         1.6740e-01, -1.1814e+00, -7.6221e-01, -1.4131e+00, -1.5331e+00,\n",
       "         9.3121e-01, -4.4463e-01,  3.0206e-02, -2.7560e-01, -9.8463e-02,\n",
       "         1.0813e+00,  3.9848e-01,  2.2014e-01,  1.0925e+00, -5.6008e-01,\n",
       "         1.1964e+00, -5.5070e-01,  1.0380e+00, -1.0265e+00,  3.5097e-01,\n",
       "         2.2691e+00,  2.7317e+00, -1.0794e-01,  2.3414e-01, -1.4489e-01,\n",
       "        -6.7195e-02, -1.1898e+00, -9.3478e-01, -6.2346e-01, -1.8997e+00,\n",
       "        -2.4890e-01,  5.2393e-01,  5.4557e-01,  4.8221e-01, -1.4842e+00,\n",
       "        -5.3076e-01, -3.5362e-01, -6.6966e-01,  1.6837e-01, -6.6736e-01,\n",
       "        -6.8012e-01, -7.6425e-01, -4.9790e-01, -1.4900e+00,  1.0726e+00,\n",
       "        -1.8952e-01, -1.4052e-01,  5.2070e-01, -5.9073e-01, -3.8906e-01,\n",
       "        -6.6640e-01,  6.2050e-01, -6.1373e-01,  1.0346e+00, -7.2417e-01,\n",
       "         1.6098e+00,  1.1703e+00,  1.7575e+00,  1.7596e+00,  6.6057e-01,\n",
       "        -1.8839e-01,  6.0934e-01, -1.3429e+00,  2.8770e-01,  3.7013e-01,\n",
       "         1.9511e-01, -7.2408e-02, -1.7804e+00,  1.4454e-01, -1.0991e+00,\n",
       "        -1.4784e+00, -1.1598e+00, -5.1639e-01, -8.5627e-01, -2.2404e+00,\n",
       "        -4.8727e-01,  3.7488e-01, -1.1867e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_embeddings.weight[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b920e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4806e+00,  1.1494e+00, -5.8721e-01,  3.4110e-01, -9.6616e-01,\n",
       "        -6.8044e-01,  1.4798e+00,  1.0209e+00, -6.4485e-01,  4.5467e-01,\n",
       "         9.7513e-01, -2.6011e-01, -5.5265e-01,  8.2508e-01, -1.4231e+00,\n",
       "         4.4060e-01,  6.4321e-02, -8.1924e-01,  5.5717e-01,  1.4058e+00,\n",
       "        -1.2668e-01,  1.2402e+00, -1.9757e+00, -2.4879e-01, -1.8383e+00,\n",
       "         4.5399e-01,  7.0577e-01,  4.1375e-01, -3.5001e-01,  9.1271e-01,\n",
       "        -2.8519e+00, -1.9229e-01,  4.1333e-01,  3.0596e+00,  5.8749e-01,\n",
       "         1.4367e+00,  2.8893e-01,  1.4455e+00, -6.1530e-01,  8.0917e-01,\n",
       "        -1.2648e+00, -8.2938e-01, -2.7060e-01, -2.1032e-01, -8.6232e-01,\n",
       "         2.0441e+00, -1.2790e+00, -4.3685e-01,  1.1931e+00, -2.1604e+00,\n",
       "        -3.9213e-01,  1.1190e+00,  4.5902e-01,  4.0149e-01, -1.6754e+00,\n",
       "         1.4853e+00, -8.6224e-01,  7.9496e-01, -2.5201e-01,  9.5908e-01,\n",
       "        -1.1209e+00, -7.3761e-01, -1.3217e+00, -5.9904e-01,  6.4476e-01,\n",
       "         2.8471e-01,  1.3390e-01,  3.5054e-01,  5.6230e-01, -4.8615e-01,\n",
       "        -3.1118e-01,  9.2990e-01,  5.7935e-01,  2.2233e-01,  1.4344e+00,\n",
       "         4.5663e-01, -1.9595e+00, -1.1534e+00,  1.2830e+00,  9.4876e-01,\n",
       "        -1.3708e-02,  1.3371e+00, -2.6717e-01,  1.0768e+00,  1.3290e+00,\n",
       "        -9.4531e-01, -8.7393e-01, -9.2177e-02, -1.6729e+00, -2.0135e-01,\n",
       "         1.3144e-01, -4.9637e-01,  3.9113e-01, -8.9447e-01, -8.0635e-01,\n",
       "        -1.9653e+00,  1.2900e-01, -6.0268e-01, -8.9576e-01, -4.0272e-01,\n",
       "        -6.7903e-02, -1.1453e+00,  8.7858e-01, -6.6927e-01, -1.7156e+00,\n",
       "        -2.7316e-02, -6.5925e-02,  1.5464e+00, -1.1190e+00,  1.1412e+00,\n",
       "         8.8340e-01, -8.3873e-01,  1.5097e+00,  2.6331e-01,  2.2619e+00,\n",
       "         5.5359e-01,  1.1428e+00,  1.9601e+00,  5.8904e-02,  8.0502e-01,\n",
       "         7.2016e-01, -1.7844e+00,  1.0982e+00, -1.5447e+00, -4.6131e-01,\n",
       "        -8.6752e-01, -1.8079e+00,  1.7214e+00, -5.3701e-01, -9.5359e-01,\n",
       "        -8.6679e-01, -4.7535e-01, -5.3189e-02,  1.3112e+00, -1.6037e+00,\n",
       "        -7.3133e-01, -6.8802e-01,  5.6345e-01,  1.5042e+00, -4.6064e-01,\n",
       "         1.7296e+00,  9.6755e-01,  5.4238e-01,  1.5271e+00, -3.9871e-01,\n",
       "        -1.3411e+00,  1.1894e+00,  1.9720e-01,  7.2624e-01,  1.5924e+00,\n",
       "         4.2513e-01, -6.6320e-01,  6.2654e-01,  6.4669e-01, -3.6786e+00,\n",
       "        -3.6719e-01, -9.2850e-01, -5.3840e-01, -5.4363e-03, -2.6112e+00,\n",
       "        -7.4516e-01, -5.2917e-01,  3.6458e-01, -7.1159e-01, -9.8547e-02,\n",
       "         2.9188e-01,  1.5106e+00, -6.9753e-01, -9.0084e-01, -6.5161e-02,\n",
       "         1.5161e-01,  1.7725e+00, -3.0930e-01,  2.0916e-01, -7.3747e-01,\n",
       "         1.8570e+00,  3.7338e-01,  3.1041e-01,  9.1891e-02, -1.0607e+00,\n",
       "         1.3635e+00,  1.0482e-01, -4.4561e-01, -1.2257e+00, -2.1716e-02,\n",
       "        -2.5923e-01,  2.2917e-01,  1.1660e+00, -1.6268e+00,  2.9900e-01,\n",
       "         3.6142e-01,  2.0208e+00, -8.5239e-01,  1.2435e+00,  8.9065e-01,\n",
       "        -5.4252e-01, -3.4534e-01,  6.5524e-01,  8.6506e-01, -7.8777e-01,\n",
       "         2.8030e-01, -6.2822e-01,  1.0311e+00,  7.4808e-01, -8.4824e-01,\n",
       "         6.2454e-01, -2.3669e-01,  1.3441e+00,  1.5451e+00,  6.1847e-01,\n",
       "         2.0130e-02, -1.5932e-01, -6.5844e-02,  1.0807e+00,  4.6751e-01,\n",
       "        -1.2978e+00, -8.9142e-01,  1.3170e+00, -1.6631e-01,  1.3730e+00,\n",
       "         4.2081e-01,  1.0181e+00, -9.4213e-01,  1.1352e+00,  4.1957e-01,\n",
       "         1.5855e+00,  9.1275e-02, -3.6226e-01,  3.3849e-01,  6.4666e-01,\n",
       "         3.5273e-01, -4.5058e-01,  6.6296e-01,  4.7491e-02,  3.2377e-01,\n",
       "        -8.5350e-01,  9.8457e-01,  2.8384e-01, -2.1577e-01, -1.2720e+00,\n",
       "         2.1114e-01,  1.2666e-01,  1.3388e+00,  1.2089e+00, -5.2565e-01,\n",
       "        -4.1388e-01,  7.4632e-01, -9.0741e-01, -2.6017e-01, -2.0908e+00,\n",
       "        -9.9265e-01, -3.4775e-02,  2.3580e-01, -7.8616e-01, -7.9570e-01,\n",
       "         6.9609e-01,  4.6822e-01, -1.3527e+00, -2.4007e-01, -6.8607e-02,\n",
       "        -1.6815e+00, -1.3314e+00, -2.9002e-01, -1.1898e+00, -7.8971e-01,\n",
       "         1.1903e+00, -1.6616e+00, -3.9933e-01,  2.0640e+00, -4.1961e-01,\n",
       "        -1.2068e+00,  1.1924e+00, -1.2841e-01, -1.0397e+00, -2.6552e+00,\n",
       "        -3.0464e-01,  4.7696e-01,  9.2623e-01,  9.4342e-01,  1.9541e+00,\n",
       "        -1.5548e-01,  4.6739e-01, -9.1994e-01,  9.1252e-01,  1.3151e+00,\n",
       "        -1.7422e-01,  3.2951e-01,  6.8583e-01,  3.4387e-01,  1.3365e-01,\n",
       "         1.5275e+00, -8.0921e-01, -6.3767e-01, -9.6998e-01,  7.7459e-02,\n",
       "        -5.6349e-01, -3.5400e-01, -3.3130e-01, -1.0143e-01,  2.2533e-01,\n",
       "        -1.4214e+00, -9.5169e-01, -1.4479e+00,  5.1408e-01,  2.0303e-01,\n",
       "         1.3865e+00, -3.3901e-02, -1.3362e+00,  5.5733e-01,  6.7237e-01,\n",
       "         2.5105e+00,  7.1927e-02,  6.1087e-01, -1.8296e+00,  4.0894e-01,\n",
       "         2.0382e-01,  5.5677e-01,  2.5820e+00, -3.7894e-01,  2.3342e+00,\n",
       "        -8.0207e-01, -6.5994e-01, -8.5212e-02,  3.8427e-01,  2.0897e+00,\n",
       "        -1.3515e+00,  3.8728e-02,  8.4032e-02, -9.9028e-01,  9.0995e-01,\n",
       "         7.2564e-01, -6.2936e-01, -4.3469e-01,  1.1881e+00, -1.0438e+00,\n",
       "         6.4239e-01,  1.1400e-01,  4.8259e-01,  6.3165e-01, -2.2215e-01,\n",
       "        -1.5170e+00, -6.9187e-01, -1.0643e+00, -6.7932e-01, -1.9437e+00,\n",
       "         1.2207e+00, -1.6049e-01,  7.1282e-01,  6.4900e-01,  2.9452e-01,\n",
       "         8.9943e-01, -9.7410e-01, -1.0591e-01, -1.8094e-01,  2.0732e-01,\n",
       "        -1.3337e+00,  8.7626e-01,  7.4710e-01, -9.3808e-01,  4.0059e-01,\n",
       "         1.2590e+00,  1.3096e-01, -3.4083e-01, -3.1034e-01,  5.5533e-03,\n",
       "         1.2811e+00,  8.0833e-01,  1.8739e+00,  1.5303e+00, -9.6257e-02,\n",
       "         8.4393e-02, -2.9808e-01, -1.0107e+00, -7.8493e-02,  7.5831e-01,\n",
       "        -4.3388e-01, -1.0062e+00, -3.6825e-01,  1.3842e+00,  3.0491e-01,\n",
       "         1.6549e+00, -1.0629e+00,  5.5171e-02,  3.4689e-01,  1.4238e+00,\n",
       "         1.0857e+00, -1.0102e+00,  4.7217e-01,  1.3977e+00, -2.2216e+00,\n",
       "        -3.5334e-01,  8.1660e-01, -8.3455e-01, -1.0060e+00, -2.8984e-01,\n",
       "         1.5708e+00, -3.9586e-01,  8.6622e-01, -8.7278e-01,  1.3238e+00,\n",
       "        -6.9462e-01,  2.8858e-01,  1.0229e-03,  1.8800e+00,  2.1919e+00,\n",
       "        -6.8833e-01,  5.8012e-01,  1.9045e+00, -2.4699e+00, -1.3532e-01,\n",
       "        -6.5404e-01, -1.0923e+00,  8.0679e-01,  2.2737e-01, -6.6157e-01,\n",
       "        -1.4445e+00,  1.3440e+00, -1.6606e-01,  1.1486e+00,  7.0918e-01,\n",
       "         6.2331e-01, -2.7409e+00,  1.6238e-01,  6.5742e-01,  2.0533e-01,\n",
       "         6.8189e-01, -1.4750e+00, -3.7774e-01,  4.4645e-01, -2.8724e-01,\n",
       "         7.8269e-01, -4.2502e-01,  1.2002e+00, -1.3806e+00,  1.2631e+00,\n",
       "         2.7702e-01,  2.2034e+00, -1.4554e+00,  8.3099e-01, -6.1134e-01,\n",
       "         5.3167e-01, -1.9271e+00,  7.7040e-01,  1.1284e-01, -8.3661e-01,\n",
       "        -1.9810e+00,  9.9106e-01, -1.4497e+00,  8.8939e-01,  1.9171e-01,\n",
       "         7.8512e-01, -1.0113e+00, -2.3621e-01,  2.1686e+00,  1.4079e+00,\n",
       "        -1.8035e+00, -1.1305e-01, -5.0796e-01, -7.3925e-02, -8.3601e-02,\n",
       "        -3.1519e-01, -6.9396e-01, -8.7792e-01,  6.3875e-01, -9.5480e-01,\n",
       "         6.1161e-01, -4.7895e-01, -3.0301e-02, -6.3752e-01, -3.3432e-01,\n",
       "         8.1934e-01,  1.8677e+00,  1.1208e+00, -1.2953e-01, -5.8138e-03,\n",
       "         4.3673e-01, -1.0646e+00, -7.2428e-01, -2.6414e-01, -7.3028e-01,\n",
       "        -5.5292e-04,  5.9216e-02, -1.2919e+00,  1.4239e+00, -6.3704e-01,\n",
       "         5.8581e-01, -2.2942e-01,  2.4246e-01,  9.1875e-01, -9.0467e-01,\n",
       "        -8.7748e-03, -2.9230e-01, -6.7927e-01, -1.0429e+00,  7.9479e-01,\n",
       "        -1.3920e+00, -9.5178e-01,  1.8612e+00, -1.1673e+00,  4.1003e-01,\n",
       "         1.3643e+00,  1.0532e+00,  7.8576e-02,  1.3271e+00,  1.0343e+00,\n",
       "         6.2484e-01, -7.2278e-01,  1.7685e+00,  1.8828e+00,  1.6424e+00,\n",
       "        -6.2228e-01, -2.2081e-01,  2.4602e-01,  2.9991e-01,  4.4085e-01,\n",
       "        -5.3887e-01,  1.0393e+00, -7.2065e-02,  1.8600e+00, -4.6261e-01,\n",
       "         7.2387e-02, -7.9669e-01,  1.6485e+00,  8.4639e-01,  5.8363e-01,\n",
       "         9.4985e-02, -4.8394e-01,  2.0662e-02,  4.2622e-01,  3.6928e-01,\n",
       "        -1.6259e-01, -2.2536e-01, -2.1832e-01,  9.4435e-01,  2.9645e-01,\n",
       "         6.4694e-01,  8.2726e-01, -1.2384e-01,  9.7578e-01, -1.5389e+00,\n",
       "        -2.6448e-01,  7.6053e-01,  1.0182e+00, -4.9530e-01, -2.9890e-01,\n",
       "        -1.4383e+00, -8.7091e-01, -4.8038e-01, -9.8328e-01, -2.1150e-01,\n",
       "        -1.6727e-01,  4.9033e-01,  4.6857e-01,  1.3823e+00, -8.7035e-01,\n",
       "         6.6058e-02,  5.4142e-01,  8.2594e-01, -3.7667e-01,  7.4486e-01,\n",
       "        -5.2552e-01,  4.4376e-01,  6.8982e-01, -5.4374e-01, -5.5373e-01,\n",
       "         2.3212e-01, -9.9483e-01,  1.8813e+00, -8.4925e-02, -1.4986e+00,\n",
       "         3.6889e-02, -9.5666e-01,  4.0709e-01,  1.0792e+00, -1.0584e+00,\n",
       "         5.0961e-02, -4.8019e-01, -1.6209e+00, -3.3559e-01, -1.0538e+00,\n",
       "         8.0755e-01, -4.4271e-02,  4.6017e-01, -7.1007e-01,  1.7470e+00,\n",
       "        -1.1710e-01, -1.2056e+00, -7.7926e-01,  3.9268e-01,  5.2909e-01,\n",
       "         5.9890e-01,  2.6364e-01,  4.6716e-01, -4.7520e-01,  1.1435e+00,\n",
       "         1.6602e-01,  6.3273e-02,  1.2267e+00,  4.1416e-02, -8.3262e-01,\n",
       "        -4.5457e-01, -6.0224e-01,  1.0620e+00, -1.2958e+00,  1.6321e+00,\n",
       "        -7.7012e-01,  1.0906e+00, -1.3219e+00, -5.3683e-02,  3.7440e-01,\n",
       "         8.4781e-01, -3.9903e-01,  9.7048e-02,  1.4825e+00, -2.0773e-02,\n",
       "        -2.5898e-01,  1.5640e+00,  5.3352e-01, -5.6498e-01, -1.8413e+00,\n",
       "        -6.1724e-01,  3.6053e-01,  3.1030e-02,  9.1261e-01, -1.0752e-01,\n",
       "        -4.7174e-01,  8.5526e-01, -1.6942e+00, -2.2468e-01, -7.3252e-01,\n",
       "        -2.4369e-02,  2.5152e+00,  2.0314e-01,  1.8607e-01, -9.8657e-02,\n",
       "        -1.4285e+00, -1.3111e+00, -1.7763e-01, -4.8207e-01,  1.9608e-01,\n",
       "        -3.8767e-01, -1.9659e-01,  4.3509e-01, -4.7211e-01,  1.5172e+00,\n",
       "         1.2640e+00, -4.7858e-01, -1.0568e+00, -2.1205e+00,  1.5038e+00,\n",
       "         8.5351e-01,  1.5540e+00,  3.3679e-01,  3.2608e-01, -8.2012e-01,\n",
       "        -2.2381e-01,  7.0846e-01,  7.7961e-02, -3.2011e-02,  5.7434e-01,\n",
       "         1.6161e-01,  5.6816e-01, -3.4197e-01,  7.2320e-01, -3.4196e-01,\n",
       "         4.7898e-01, -7.4160e-01, -1.2542e+00, -3.6028e-01,  2.0627e+00,\n",
       "        -4.2340e-01, -7.5879e-01, -1.2850e+00,  8.4815e-01,  6.1592e-02,\n",
       "        -1.1300e+00,  5.5199e-01, -1.6606e+00, -9.5834e-01, -1.3933e+00,\n",
       "         1.6411e+00,  1.8321e+00,  1.8565e+00, -9.7623e-01, -1.3251e+00,\n",
       "        -3.1267e-01, -1.1773e+00, -7.7704e-01,  5.7305e-01, -9.2236e-01,\n",
       "         1.6740e-01, -1.1814e+00, -7.6221e-01, -1.4131e+00, -1.5331e+00,\n",
       "         9.3121e-01, -4.4463e-01,  3.0206e-02, -2.7560e-01, -9.8463e-02,\n",
       "         1.0813e+00,  3.9848e-01,  2.2014e-01,  1.0925e+00, -5.6008e-01,\n",
       "         1.1964e+00, -5.5070e-01,  1.0380e+00, -1.0265e+00,  3.5097e-01,\n",
       "         2.2691e+00,  2.7317e+00, -1.0794e-01,  2.3414e-01, -1.4489e-01,\n",
       "        -6.7195e-02, -1.1898e+00, -9.3478e-01, -6.2346e-01, -1.8997e+00,\n",
       "        -2.4890e-01,  5.2393e-01,  5.4557e-01,  4.8221e-01, -1.4842e+00,\n",
       "        -5.3076e-01, -3.5362e-01, -6.6966e-01,  1.6837e-01, -6.6736e-01,\n",
       "        -6.8012e-01, -7.6425e-01, -4.9790e-01, -1.4900e+00,  1.0726e+00,\n",
       "        -1.8952e-01, -1.4052e-01,  5.2070e-01, -5.9073e-01, -3.8906e-01,\n",
       "        -6.6640e-01,  6.2050e-01, -6.1373e-01,  1.0346e+00, -7.2417e-01,\n",
       "         1.6098e+00,  1.1703e+00,  1.7575e+00,  1.7596e+00,  6.6057e-01,\n",
       "        -1.8839e-01,  6.0934e-01, -1.3429e+00,  2.8770e-01,  3.7013e-01,\n",
       "         1.9511e-01, -7.2408e-02, -1.7804e+00,  1.4454e-01, -1.0991e+00,\n",
       "        -1.4784e+00, -1.1598e+00, -5.1639e-01, -8.5627e-01, -2.2404e+00,\n",
       "        -4.8727e-01,  3.7488e-01, -1.1867e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = model.word_embeddings(input_ids)\n",
    "input_ids.shape, emb.shape\n",
    "emb[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2225d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = model.position_embeddings(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dbe7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_emb = model.token_type_embeddings(torch.zeros_like(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ead24ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31, 51, 12, 23, 99],\n",
       "        [15,  5,  1,  0,  0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8bf4bbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7394, -0.1369,  1.4752,  ..., -1.6244,  1.8485,  0.4632],\n",
       "         [ 0.7394, -0.1369,  1.4752,  ..., -1.6244,  1.8485,  0.4632],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100]],\n",
       "\n",
       "        [[ 0.7394, -0.1369,  1.4752,  ..., -1.6244,  1.8485,  0.4632],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100],\n",
       "         [ 0.2977,  0.8332, -0.5640,  ..., -0.7253,  0.8034, -0.3100]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if token_type_ids is None:\n",
    "    token_type_ids = torch.zeros_like(input_ids)\n",
    "token_type_embeddings = model.token_type_embeddings(token_type_ids)\n",
    "token_type_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "861cd6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3823e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = input_ids.size(1)\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9e48541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, tensor([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = input_ids.size(1) # 문장 길이\n",
    "position_ids = torch.arange(\n",
    "    seq_length, dtype=torch.long, device=input_ids.device)\n",
    "seq_length, position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e24180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "241d8dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " tensor([[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "position_ids.shape, position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b9970207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1813,  0.0983, -0.8991,  ..., -0.1996,  0.3542,  1.7562],\n",
       "         [-0.2457, -0.2471, -0.0510,  ..., -2.1774,  0.8956, -0.6549],\n",
       "         [-0.5985,  1.6512, -0.8037,  ...,  1.5534,  0.1627,  2.2195],\n",
       "         [-1.6036,  0.4944,  0.6576,  ...,  1.2255,  0.8074,  2.3766],\n",
       "         [ 0.2873, -0.4889, -0.5152,  ..., -0.4286,  1.9095, -0.5513]],\n",
       "\n",
       "        [[-0.1813,  0.0983, -0.8991,  ..., -0.1996,  0.3542,  1.7562],\n",
       "         [-0.2457, -0.2471, -0.0510,  ..., -2.1774,  0.8956, -0.6549],\n",
       "         [-0.5985,  1.6512, -0.8037,  ...,  1.5534,  0.1627,  2.2195],\n",
       "         [-1.6036,  0.4944,  0.6576,  ...,  1.2255,  0.8074,  2.3766],\n",
       "         [ 0.2873, -0.4889, -0.5152,  ..., -0.4286,  1.9095, -0.5513]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embeddings = model.position_embeddings(position_ids)\n",
    "position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a896bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1813,  0.0983, -0.8991,  ..., -0.1996,  0.3542,  1.7562],\n",
       "         [-0.2457, -0.2471, -0.0510,  ..., -2.1774,  0.8956, -0.6549],\n",
       "         [-0.5985,  1.6512, -0.8037,  ...,  1.5534,  0.1627,  2.2195],\n",
       "         [-1.6036,  0.4944,  0.6576,  ...,  1.2255,  0.8074,  2.3766],\n",
       "         [ 0.2873, -0.4889, -0.5152,  ..., -0.4286,  1.9095, -0.5513]],\n",
       "\n",
       "        [[-0.1813,  0.0983, -0.8991,  ..., -0.1996,  0.3542,  1.7562],\n",
       "         [-0.2457, -0.2471, -0.0510,  ..., -2.1774,  0.8956, -0.6549],\n",
       "         [-0.5985,  1.6512, -0.8037,  ...,  1.5534,  0.1627,  2.2195],\n",
       "         [-1.6036,  0.4944,  0.6576,  ...,  1.2255,  0.8074,  2.3766],\n",
       "         [ 0.2873, -0.4889, -0.5152,  ..., -0.4286,  1.9095, -0.5513]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = model.position_embeddings(position_ids)\n",
    "pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f0b79b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9225,  1.1107, -0.0111,  ..., -2.3113,  2.5776,  1.0327],\n",
       "         [ 0.4528,  1.4399,  0.8410,  ..., -4.3547,  3.6022, -1.0994],\n",
       "         [ 0.6467,  0.2667, -0.0129,  ...,  0.8187,  2.8086,  3.1922],\n",
       "         [ 1.5365, -0.7661,  1.9692,  ..., -0.5671,  2.0402,  2.0562],\n",
       "         [ 0.8985, -0.8304,  1.7427,  ..., -0.9196,  3.9093,  0.1902]],\n",
       "\n",
       "        [[ 0.6833,  0.4515,  0.7226,  ..., -2.7106,  2.2928,  3.3426],\n",
       "         [ 0.4065, -0.2599, -0.2544,  ..., -4.7195,  4.0781, -0.2462],\n",
       "         [ 0.0629,  1.6372, -0.0887,  ...,  1.0221,  1.7888,  4.6532],\n",
       "         [-0.8642,  0.3574,  2.1328,  ..., -0.3988,  2.6559,  2.8398],\n",
       "         [ 1.0267, -0.6259,  0.9600,  ..., -2.0530,  3.7580, -0.0881]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb + pos_emb + tok_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "774e6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa2d4d",
   "metadata": {},
   "source": [
    "## 8.2.5 BertLayer 모듈\n",
    "- BertLayer는 Transformer부분에 해당.\n",
    "- 서브 네트워크로서 Self-Attention을 계산하는 BertAttention과 Self-Attention의 출력을 처리하는 전결합 층인 BertIntermediate, 그리고 Self-Attention 출력과 BertIntermediate에서 처리한 특징량을 더하는 BertOutput 세 가지로 구성됩니다.\n",
    "- BertLayer에 대한 입력은 Embedding 모듈의 출력 또는 앞단의 BertLayer에서의 출력이며 크기는 (batch_size, seq_len, hidden_size)입니다. - BertLayer구현에서 7장 Transformer와 두 가지 다른 점이 있습니다.\n",
    "- 첫째, BertIntermediate 전결합 층 뒤의 활성화 함수에 GELU함수를 사용하는 점입니다. GELU는 기본적으로 RELU와 같은 형태의 함수입니다. 입력이 0이지만 ReLU출력이 거친(매끄러운 변화가 아니라 급격환 변화) 반면 GELU는 입력 0 근처의 출력이 매끄러운 형태입니다.\n",
    "- 둘쩨, Attention이 Multi-Headed Self-Attention입니다. Transformer도 Multi-Headed Self-Attention이지만 7장에서는 이해를 돕기 위하여 단일 Self-Attention으로 구현하였습니다. Multi-Headed Self-Attention은 단순히 Self-Attention이 여러 개 있는것 뿐입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35c9fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(nn.Module):\n",
    "    '''BERT의 BertLayer모듈이다. Transformer가 된다.'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        \n",
    "        # Self-Attention 부분\n",
    "        self.attention = BertAttention(config)\n",
    "        \n",
    "        # Self-Attention의 출력을 처리하는 전결합 층\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        \n",
    "        # Self-Attention에 의한 특징량과 BertLayer에 원래의 입력을 더하는 층\n",
    "        self.output = BertOutput(config)\n",
    "        \n",
    "    def forward(self, hidden_states, attention_mask, attention_show_fig=False):\n",
    "        '''\n",
    "        hidden_states : Embedder 모듈의 출력 텐서 [batch_size, seq_len, hidden_size]\n",
    "        attention_mask : Transformer의 마스크와 같은 기능의 마스킹\n",
    "        attention_show_fig : Self-Attention의 가중치를 반환할지의 플래그\n",
    "        '''\n",
    "        if attention_show_fig == True:\n",
    "            '''attention_show일 경우 attention_probs도 반환한다.'''\n",
    "            attention_output, attention_probs = self.attention(hidden_states, \n",
    "                                                               attention_mask, \n",
    "                                                               attention_show_fig)\n",
    "            \n",
    "            intermediate_output = self.intermediate(attention_output)\n",
    "            \n",
    "            layer_output = self.output(intermediate_output, attention_output)\n",
    "            \n",
    "            return layer_output, attention_probs\n",
    "        \n",
    "        elif attention_show_fig == False:\n",
    "            attention_output = self.attention(hidden_states, \n",
    "                                              attention_mask, \n",
    "                                              attention_show_fig)\n",
    "            \n",
    "            intermediate_output = self.intermediate(attention_output)\n",
    "            \n",
    "            layer_output = self.output(intermediate_output, attention_output)\n",
    "            \n",
    "            return layer_output # [batch_size, seq_length, hidden_size]\n",
    "        \n",
    "class BertAttention(nn.Module):\n",
    "    '''BertLayer 모듈의 Self-Attention 부분'''\n",
    "    def __init__(self, config):\n",
    "        super(BertAttention, self).__init__()\n",
    "        self.selfattn = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        \n",
    "    def forward(self, input_tensor, attention_mask, attention_show_fig=False):\n",
    "        '''\n",
    "        input_tensor : Embeddings 모듈 또는 앞단의 BertLayer에서의 출력\n",
    "        attention_mask : Transformer의 마스크와 같은 기능의 마스킹\n",
    "        attention_show_fig : Self-Attention의 가중치를 반환할지의 플래그\n",
    "        '''\n",
    "        if attention_show_fig == True:\n",
    "            '''attention_show일 경우 attention_probs도 반환한다.'''\n",
    "            self_output, attention_probs = self.selfattn(input_tensor, attention_mask, attention_show_fig)\n",
    "            attention_output = self.output(self_output, input_tensor)\n",
    "            return attention_output, attention_probs\n",
    "        \n",
    "        elif attention_show_fig == False:\n",
    "            self_output = self.selfattn(input_tensor, attention_mask, attention_show_fig)\n",
    "            attention_output = self.output(self_output, input_tensor)\n",
    "            return attention_output\n",
    "        \n",
    "class BertSelfAttention(nn.Module):\n",
    "    '''BertAttention의 Self-Attention이다'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertSelfAttention, self).__init__()\n",
    "        \n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        # num_attention_heads = 12\n",
    "        \n",
    "        self.attention_head_size = int(\n",
    "            config.hidden_size / config.num_attention_heads) # 768 / 12 = 64\n",
    "        self.all_head_size = self.num_attention_heads * \\\n",
    "            self.attention_head_size # = 'hidden_size' : 768\n",
    "        \n",
    "        # Self-Attention의 특징량을 작성하는 전결합 층\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        \n",
    "        # drop out\n",
    "        self.drop_out = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        \n",
    "    def transpose_for_scores(self, x):\n",
    "        '''Multi-Headed Attention용으로 텐서의 형태 변환\n",
    "        [batch_size, seq_len, hidden] -> [batch_size, 12, seq_len, hidden/12]\n",
    "        '''\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, hidden_states, attention_mask, attention_show_fig=False):\n",
    "        '''\n",
    "        hidden_states : Embeddings 모듈 또는 앞단의 BertLayer에서의 출력\n",
    "        attention_mask : Transformer의 마스크와 같은 기능의 마스킹\n",
    "        attention_show_fig : Self-Attention의 가중치를 반환할지 플래그\n",
    "        '''\n",
    "        \n",
    "        # 입력의 전결합 층에서 특징량 변환(Multi-headed Attention 전부 한꺼번에 변환)\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        \n",
    "        # Multi-Headed Attention용으로 텐서 형태 변환\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "        \n",
    "        # 특징량끼리 곱하여 비슷한 정도를 Attention_scores로 구한다.\n",
    "        attention_scores = torch.matmul(\n",
    "            query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / \\\n",
    "            math.sqrt(self.attention_head_size)\n",
    "        \n",
    "        # 마스크가 있는 부분에 마스크 적용\n",
    "        attention_scores = attention_scores + attention_mask\n",
    "        # 마스크는 곰셈이 아니라 덧셈이 직관적이지만 그 후에 소프트맥스로 정규화하므로\n",
    "        # 마스크된 부분은 -inf로 한다. attention_mask에는 원래 0이나 -inf가 있으므로 덧셈으로 한다.\n",
    "        \n",
    "        # Attention 정규화\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        \n",
    "        # 드롭아웃\n",
    "        attention_probs = self.drop_out(attention_probs)\n",
    "        \n",
    "        # Attention Map을 곱한다.\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        \n",
    "        # Multi-Headed Attention의 텐서 형태를 원래대로 되돌린다.\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        \n",
    "        # attention_show일 경우 attention_probs도 반환\n",
    "        if attention_show_fig == True:\n",
    "            return context_layer, attention_probs\n",
    "        elif attention_show_fig == False:\n",
    "            return context_layer\n",
    "        \n",
    "class BertSelfOutput(nn.Module):\n",
    "    '''BertSelfAttention의 출력을 처리하는 전결합 층이다'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertSelfOutput, self).__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # 'hidden_dropout_prob': 0.1\n",
    "        \n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        '''\n",
    "        hidden_stats : BertSelfAttention의 출력 텐서\n",
    "        input_tensor : Embeddings 모듈 또는 앞단의 BertLayer에서의 출력\n",
    "        '''\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "def gelu(x):\n",
    "    '''Gaussian Error Linear Unit라는 활성화 함수이다\n",
    "    ReLU가 0으로 거칠고 불연속적이므로 연속적으로 매끄럽게 한 셩태의 ReLU이다\n",
    "    '''\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "        \n",
    "class BertIntermediate(nn.Module):\n",
    "    '''BERT의 TransformerBlock 모듈 FeedForward'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertIntermediate, self).__init__()\n",
    "        \n",
    "        # 전결합 층 : 'hidden_size': 768, 'intermediate_size': 3072\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # 활성화 함수\n",
    "        self.intermediate_act_fn = gelu\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        '''\n",
    "        hidden_states : BertAttention의 출력\n",
    "        '''\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states) # GELU에 의한 활성화\n",
    "        return hidden_states\n",
    "    \n",
    "class BertOutput(nn.Module):\n",
    "    '''BERT의 TransformerBlock 모듈 FeedForward'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertOutput, self).__init__()\n",
    "        \n",
    "        # 전결합 층 : 'intermediate_size': 3072, 'hidden_size': 768\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        \n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        \n",
    "        # 'hidden_dropout_prob': 0.1\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        '''\n",
    "        hidden_states : BertIntermediate 출력 텐서\n",
    "        input_tensor : BertAttention 출력 텐서\n",
    "        '''\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f976ed8",
   "metadata": {},
   "source": [
    "## 8.2.6 BertLayer 모듈의 반복 부분\n",
    "- BERT_Base에서는 BertLayer 모듈(Transformer)을 12회 반복.\n",
    "- 이들을 묶어서 BertEncoder클래스로 만듭니다.\n",
    "- 단순히 BertLayer 12개를 nn.ModuleList에 기재하여 순전파.\n",
    "- 순전파 함수 forward의 인수\n",
    "    - output_all_encoded_layer인수는 반환 값으로 BertLayer에서 출력된 특징량을 12단만큼 모두 반환할지 아니면 12단 최종 층의 특징량만 반환할지 여부를 지정하는 변수.\n",
    "    - 12단의 Transformer 중간에 단어 벡터가 어떻게 변해가는지 확인하고 싶을 때 output_all_encoded_layers인수를 True로 하여 12단 만큼의 단어 벡터를 꺼낼 수 있습니다.\n",
    "    - 단순히 12단 출력만을 사용하여 자연어 처리를 작업하는 경우 False로 하여 최종 BertLayer 모듈 출력만 BertEncoder에서 출력시킨 후 사용\n",
    "    - attention_show_fig인수는 BertLayer 모듈에서 사용했던 변수와 동일\n",
    "    - Self-Attention의 가중치를 출력할지 여부를 지정합니다. BERT_Base의 Attention은 각 층이 12개인 Multi-headed Self-Attention입니다.\n",
    "    - BertEncoder에서 attention_show_fig인수를 True로 한 경우에는 BertLayer 모듈 중 12단 끝에 있는 BertLayer 모듈에서 12개의 Multi-Headed Self-Attention가중치를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ea6fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLayer 모듈의 반복 부분이다.\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        '''BertLayer 모듈의 반복 부분'''\n",
    "        super(BertEncoder, self).__init__()\n",
    "        \n",
    "        # config.num_hidden_layers의 값, 즉 12개의 BertLayer 모듈을 만든다.\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        \n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True, attention_show_fig=False):\n",
    "        '''\n",
    "        hidden_states : Embeddings 모듈 출력\n",
    "        attention_mask : Transformer의 마스크와 동일한 기능의 마스킹\n",
    "        output_all_encoded_layers : 반환 값을 전체 TransformerBlock 모듈의 출력으로 할지 마지막 층만으로 한정할지의 플래그\n",
    "        attention_show_fig : Self-Attention의 가중치를 반환할지의 플래그\n",
    "        '''\n",
    "        \n",
    "        # 반환 값으로 사용할 리스트\n",
    "        all_encoder_layers = []\n",
    "        \n",
    "        # BertLayer 모듈의 처리 반복\n",
    "        for layer_module in self.layer:\n",
    "            \n",
    "            if attention_show_fig == True:\n",
    "                '''attention_show의 경우 attention_probs도 반환'''\n",
    "                hidden_states, attention_probs = layer_module(\n",
    "                    hidden_states, attention_mask, attention_show_fig)\n",
    "            elif attention_show_fig == False:\n",
    "                hidden_states = layer_module(\n",
    "                    hidden_states, attention_mask, attention_show_fig)\n",
    "                \n",
    "            # 반환 값으로 BertLayer에서 출력된 특징량만을 사용할 경우의 처리\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "                    \n",
    "        # 반환 값으로 마지막 BertLayer에서 출력된 특징량만을 사용할 경우의 처리\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "            \n",
    "        # attention_show의 경우 attention_probs(마지막 12단)도 반환한다.\n",
    "        if attention_show_fig == True:\n",
    "            return all_encoder_layers, attention_probs\n",
    "        elif attention_show_fig == False:\n",
    "            return all_encoder_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4ec36",
   "metadata": {},
   "source": [
    "## 8.2.7 BertPooler 모듈\n",
    "- BertPooler 모듈은 BertEncoder출력에서 입력 문장의 첫 번째 단어인 [CLS]부분의 특징량 텐서(1 x 768차원)을 꺼내 전결합 층을 사용한 후 특징량을 변환하는 모듈입니다.\n",
    "- 전결합 층 뒤에 활성화 함수 Tanh을 사용하고 출력을 1에서 -1까지 범위로 합니다. 출력 텐서의 크기는 (batch_size, hidden_size)입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41b57475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPooler(nn.Module):\n",
    "    '''입력 문장의 첫 번째 단어 [cls]의 특징량을 반환하고 유지하기 위한 모듈'''\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        \n",
    "        # 전결합 층, 'hidden_size':768\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        # 첫 번째 단어의 특징량 취득\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        \n",
    "        # 전결합 층에서 특징량 변환\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        \n",
    "        # 활성화 함수 Tanh을 계산\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        \n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da244d",
   "metadata": {},
   "source": [
    "## 8.2.8 동작 확인\n",
    "- 미니 배치의 크기를 2, 각 미니 배치의 문장 길이르 5로 하여 입력을 적당히 생성\n",
    "- 길이 5에 두 문장이 포함되어 있음. 어떠한 단어까지 첫 번째 문장이고 어떠한 단어부터 두 번째 문장인지 나타내는 문장 ID와 Attention용 마스크도 생성. 이러한 입력으로 동작을 확인\n",
    "- Attention용 마스크를 확장한 extended_attention_mask 변수를 작성한다는 점을 주의해야 한다\n",
    "- Multi-Headed Self-Attention에서 Attention마스크를 사용할 수 있도록 하는 변환.\n",
    "- Attention을 적용하지 않는 부분은 시그모이드를 계산했을 때 0이 되도록 마이너스 무한의 대안으로써 -10000을 대입."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d97169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 ID열의 텐서 크기:  torch.Size([2, 5])\n",
      "입력 마스크의 텐서 크기:  torch.Size([2, 5])\n",
      "입력 문장 ID의 텐서 크기:  torch.Size([2, 5])\n",
      "확장된 마스크의 텐서 크기:  torch.Size([2, 1, 1, 5])\n",
      "BertEmbeddings의 출력 텐서 크기: torch.Size([2, 5, 768])\n",
      "BertEncoder 최후 층의 출력 텐서 크기: torch.Size([2, 5, 768])\n",
      "BertPooler의 출력 텐서 크기: torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인\n",
    "\n",
    "# 입력 단어 ID열 batch_size는 두 가지\n",
    "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
    "print('입력 단어 ID열의 텐서 크기: ', input_ids.shape)\n",
    "# 마스크\n",
    "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
    "print('입력 마스크의 텐서 크기: ', attention_mask.shape)\n",
    "\n",
    "# 문장의 ID, 두 미니 배치 각각에 대한 0은 첫 번째 문장을, 1은 두 번째 문장을 나타낸다.\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
    "print('입력 문장 ID의 텐서 크기: ', token_type_ids.shape)\n",
    "\n",
    "# BERT의 각 모듈 준비\n",
    "embeddings = BertEmbeddings(config)\n",
    "encoder = BertEncoder(config)\n",
    "pooler = BertPooler(config)\n",
    "\n",
    "# 마스크 변형 [batch_size, 1, 1, seq_length]로 한다.\n",
    "# Attention을 적용하지 않는 부분은 마이너스 무한으로 하고 위하여 -10000을 곱한다.\n",
    "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "print('확장된 마스크의 텐서 크기: ', extended_attention_mask.shape)\n",
    "\n",
    "# 순전파\n",
    "out1 = embeddings(input_ids, token_type_ids)\n",
    "print('BertEmbeddings의 출력 텐서 크기:', out1.shape)\n",
    "\n",
    "out2 = encoder(out1, extended_attention_mask)\n",
    "# out2는 [minibatch, seq_length, embedding_dim]이 12개 리스트\n",
    "print('BertEncoder 최후 층의 출력 텐서 크기:', out2[0].shape)\n",
    "\n",
    "out3 = pooler(out2[-1]) # out2는 12층의 특징량 리스트가 되어 가장 마지막을 사용\n",
    "print('BertPooler의 출력 텐서 크기:', out3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ebd89de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]),\n",
       " torch.Size([2, 1, 1, 5]),\n",
       " tensor([[[[1, 1, 1, 1, 1]]],\n",
       " \n",
       " \n",
       "         [[[1, 1, 1, 0, 0]]]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "attention_mask.shape, extended_attention_mask.shape, extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04dc256f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 1, 5]),\n",
       " tensor([[[[1., 1., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1., 0., 0.]]]]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "extended_attention_mask.shape, extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d46c222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 1, 5]),\n",
       " tensor([[[[    -0.,     -0.,     -0.,     -0.,     -0.]]],\n",
       " \n",
       " \n",
       "         [[[    -0.,     -0.,     -0., -10000., -10000.]]]]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "extended_attention_mask.shape, extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649f34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0833bcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5183,  0.8744, -0.6474,  ..., -0.1523,  0.0000, -1.8388],\n",
       "         [-0.0000, -2.2031,  0.7122,  ...,  0.2697, -0.0000, -1.0999],\n",
       "         [-0.5974,  0.7153, -1.2055,  ...,  1.6777,  0.6225,  0.5458],\n",
       "         [ 1.4920,  0.1230, -0.0000,  ...,  0.1844, -1.1844,  0.2829],\n",
       "         [-0.4239,  0.1712, -1.7108,  ..., -0.6405, -1.0815,  0.5137]],\n",
       "\n",
       "        [[ 1.0652, -0.2365, -0.2122,  ...,  1.3648,  1.8276, -0.9468],\n",
       "         [ 0.7128, -2.1402,  0.8725,  ..., -1.3434, -1.8721, -0.1389],\n",
       "         [-0.4667,  0.1940, -0.7100,  ...,  0.3417,  0.9378,  0.1089],\n",
       "         [ 0.0000,  0.5578, -0.6825,  ...,  0.3566, -2.2600,  0.7890],\n",
       "         [-1.0589, -0.3668, -1.6822,  ..., -1.2145, -1.0332,  1.1162]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7d858d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 768]),\n",
       " 12,\n",
       " torch.Size([2, 5, 768]),\n",
       " tensor([[[ 5.0371e-01,  8.2984e-01, -5.0412e-01,  ...,  7.2131e-02,\n",
       "            1.7786e-01, -2.2644e+00],\n",
       "          [ 5.6436e-01, -1.9141e+00,  6.7024e-01,  ...,  4.3499e-01,\n",
       "            4.4968e-01, -9.2028e-01],\n",
       "          [-1.4776e-01,  9.9116e-01, -1.0737e+00,  ...,  1.8967e+00,\n",
       "            4.7691e-01,  3.4587e-01],\n",
       "          [ 1.6951e+00,  4.8224e-01, -1.2518e-01,  ...,  4.8702e-01,\n",
       "           -1.2383e+00,  2.1447e-01],\n",
       "          [-2.1283e-01,  7.6516e-01, -1.3443e+00,  ..., -5.4793e-01,\n",
       "           -9.2073e-01,  3.2209e-01]],\n",
       " \n",
       "         [[ 1.1051e+00, -2.8525e-01,  3.5683e-01,  ...,  1.5262e+00,\n",
       "            1.9065e+00, -1.0319e+00],\n",
       "          [ 6.1323e-01, -1.6044e+00,  1.1423e+00,  ..., -8.1751e-01,\n",
       "           -1.8087e+00, -3.5258e-04],\n",
       "          [ 5.6175e-02, -1.1095e-01, -2.0454e-01,  ...,  1.0018e+00,\n",
       "            6.1780e-01, -8.1472e-02],\n",
       "          [-1.1993e-02,  4.7299e-01, -4.4785e-01,  ...,  8.5274e-01,\n",
       "           -1.8880e+00,  4.9705e-01],\n",
       "          [-8.5024e-01, -1.3195e-01, -1.0566e+00,  ..., -9.5625e-01,\n",
       "           -7.2232e-01,  5.4782e-01]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = encoder(out1, extended_attention_mask)\n",
    "out1.shape, len(out2), out2[0].shape, out2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d9d1d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macos/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(510)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax()\n",
    "torch.argmax(softmax(out3[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110843aa",
   "metadata": {},
   "source": [
    "## 8.2.9 모두 연결하여 BERT모델로\n",
    "- 동작을 확인한 후 문제가 없다면 모두 연결한 BERT 모델로 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89d406c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    '''모듈을 전부 연결한 BERT 모델'''\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__()\n",
    "        \n",
    "        # 세 가지 모듈 작성\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True,\n",
    "                attention_show_fig=False):\n",
    "        '''\n",
    "        input_ids : [batch_size, sequence_length] 문장의 단어 ID 나열\n",
    "        token_type_ids : [batch_size, sequence_length] 각 단어가 첫 번째 문장인지 두 번째 문장인지 나타내는 id\n",
    "        attention_mask: Transformer의 마스크와 같은 기능의 마스킹\n",
    "        output_all_encoded_layers : 마지막 출력에 12단의 Transformer 모두 리스트로 반환할지 마지막만인지 지정\n",
    "        attention_show_fig : Self-Attention의 가중치를 반환할지 플래그\n",
    "        '''\n",
    "        \n",
    "        # Attention 마스크와 첫 번째, 두 번째 문장의 id가 없으면 작성\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.one_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "            \n",
    "        # 마스크 변형 [minibatch, 1, 1, seq_length]로 한다.\n",
    "        # 나중에 Multi-Headed Self-Attention에서 사용할 수 있는 형태로 하기 위하여\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        # 마스크는 0, 1 이지만 소프트맥스를 계산할 때 마스크가 되도록 0과 -inf로 한다.\n",
    "        # -inf 대신 -10000으로 한다\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        \n",
    "        # 순전파 시킨다\n",
    "        # BertEmbeddings 모듈\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "        \n",
    "        # BertLayer 모듈(Transformer)을 반복하는 BertEncoder 모듈\n",
    "        if attention_show_fig == True:\n",
    "            '''attention_show의 경우 attention_probs도 반환'''\n",
    "            \n",
    "            encoded_layers, attention_probs = self.encoder(embedding_output,\n",
    "                                                           extended_attention_mask,\n",
    "                                                           output_all_encoded_layers,\n",
    "                                                           attention_show_fig)\n",
    "            \n",
    "        elif attention_show_fig == False:\n",
    "            encoded_layers = self.encoder(embedding_output,\n",
    "                                          extended_attention_mask,\n",
    "                                          output_all_encoded_layers,\n",
    "                                          attention_show_fig)\n",
    "            \n",
    "        # BertPooler 모듈\n",
    "        # 인코더의 맨 마지막 BertLayer에서 출력된 특징량 사용\n",
    "        pooled_output = self.pooler(encoded_layers[-1])\n",
    "        \n",
    "        # output_all_encoded_layer가 False인 경우는 리스트가 아닌 텐서를 반환\n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "            \n",
    "        # attention_show의 경우 attention_probs(가장 마지막)도 반환한다.\n",
    "        if attention_show_fig == True:\n",
    "            return encoded_layers, pooled_output, attention_probs\n",
    "        elif attention_show_fig == False:\n",
    "            return encoded_layers, pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "155c4c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (selfattn): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (drop_out): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = BertModel(config)\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9559dc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "BertModel                                          --\n",
       "├─BertEmbeddings: 1-1                              --\n",
       "│    └─Embedding: 2-1                              23,440,896\n",
       "│    └─Embedding: 2-2                              393,216\n",
       "│    └─Embedding: 2-3                              1,536\n",
       "│    └─BertLayerNorm: 2-4                          1,536\n",
       "│    └─Dropout: 2-5                                --\n",
       "├─BertEncoder: 1-2                                 --\n",
       "│    └─ModuleList: 2-6                             --\n",
       "│    │    └─BertLayer: 3-1                         7,087,872\n",
       "│    │    └─BertLayer: 3-2                         7,087,872\n",
       "│    │    └─BertLayer: 3-3                         7,087,872\n",
       "│    │    └─BertLayer: 3-4                         7,087,872\n",
       "│    │    └─BertLayer: 3-5                         7,087,872\n",
       "│    │    └─BertLayer: 3-6                         7,087,872\n",
       "│    │    └─BertLayer: 3-7                         7,087,872\n",
       "│    │    └─BertLayer: 3-8                         7,087,872\n",
       "│    │    └─BertLayer: 3-9                         7,087,872\n",
       "│    │    └─BertLayer: 3-10                        7,087,872\n",
       "│    │    └─BertLayer: 3-11                        7,087,872\n",
       "│    │    └─BertLayer: 3-12                        7,087,872\n",
       "├─BertPooler: 1-3                                  --\n",
       "│    └─Linear: 2-7                                 590,592\n",
       "│    └─Tanh: 2-8                                   --\n",
       "===========================================================================\n",
       "Total params: 109,482,240\n",
       "Trainable params: 109,482,240\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.summary(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b175104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_layers의 텐서 크기: torch.Size([2, 5, 768])\n",
      "pooled_output의 텐서 크기: torch.Size([2, 768])\n",
      "attention_probs의 텐서 크기: torch.Size([2, 12, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인\n",
    "# 입력 준비\n",
    "input_ids = torch.LongTensor([[31, 52, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
    "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
    "\n",
    "# BERT 모델을 만든다.\n",
    "net = BertModel(config)\n",
    "\n",
    "# 순전파\n",
    "encoded_layers, pooled_output, attention_probs = net(\n",
    "    input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, attention_show_fig=True)\n",
    "\n",
    "print('encoded_layers의 텐서 크기:', encoded_layers.shape)\n",
    "print('pooled_output의 텐서 크기:', pooled_output.shape)\n",
    "print('attention_probs의 텐서 크기:', attention_probs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
