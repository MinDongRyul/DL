{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d60cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4eb791",
   "metadata": {},
   "source": [
    "## 8.4.1 IMDb 데이터를 읽고 데이터 로더 작성(BERT의 Tokenizer사용)\n",
    "- 첫째, 단어 분할 Tokenizer에 BERT용 Tokenizer를 사용합니다. 7장에서는 공백으로 구분하는 함수를 직접 만들었찌만 이번에는 앞서 구현한 BertTokenizer 클래스의 tokenize 함수를 사용합니다.\n",
    "- 둘째, torchtext에서 데이터 로더를 작성할 때 vocabulary인 TEXT.vocab을 만드는 방법이 다릅니다. 7장에서는 훈련 데이터에 포함된 단어로 vocabulary를 작성했습니다. BERT는 미리 준비된 vocab 폴더 내 bert-base-uncased-vocab.txt의 30,522단어(정확하게는 서브워드)를 모두 사용한 vocabulary를 만듭니다. BERT의 모든 단어를 사용하여 BertEmbeddings모듈을 작성하기 때문입니다.\n",
    "- 두 가지 차이점에 주의하면서 구현합니다.\n",
    "- 먼저 문장의 전처리와 단어 분할을 묶은 tokenizer_with_preprocessing 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e879b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 및 단어 분할을 묶은 함수 작성\n",
    "import re\n",
    "import string\n",
    "from utils.bert import BertTokenizer\n",
    "# utils 폴더의 bert.py를 불러들인다.\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    '''IMDb 전처리'''\n",
    "    # 개행 코드 삭제\n",
    "    text = re.sub('<br />', '', text)\n",
    "    \n",
    "    # 쉼표, 마침표 외의 기호를 공백(스페이스)으로 대체\n",
    "    for p in string.punctuation:\n",
    "        if (p == '.') or (p == ','):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, ' ')\n",
    "    \n",
    "    # 마침표 등의 전후에 공백을 넣는다\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace(',', ' , ')\n",
    "    return text\n",
    "\n",
    "# 단어 분할용 Tokenizer 준비\n",
    "tokenizer_bert = BertTokenizer(\n",
    "    vocab_file='./vocab/bert-base-uncased-vocab.txt', do_lower_case=True)\n",
    "\n",
    "# 전처리와 단어 분할을 묶은 함수 정의\n",
    "# 단어 분할 함수를 전달하므로 tokenizer_bert대신 tokenizer_bert.tokenize를 전달하는 점에 주의\n",
    "def tokenizer_with_preprocessing(text, tokenizer=tokenizer_bert.tokenize):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer(text) # tokenizer_bert\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 읽었을 때 내용에 수행할 처리 정의\n",
    "max_length = 256\n",
    "\n",
    "TEXT = torchtext.data.Field(sequential=True,\n",
    "                           tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
    "                           lower=True, include_lengths=True, batch_first=True,\n",
    "                           fix_length=max_length, init_token='[CLS]',\n",
    "                           eos_token='[SEP]', pad_token='[PAD]',\n",
    "                           unk_token='[UNK]')\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# 각 인수 재확인\n",
    "# sequential: 데이터의 길이가 달라질 수 있는가? 문장은 길이가 다양하므로 True, 라벨은 False\n",
    "# tokenize: 문장을 읽을 때 전처리 및 단어 분할 함수 정의\n",
    "# use_vocab: vocabulary에 단어를 추가할지 여부\n",
    "# lower: 알파벳일 있을 때 소문자로 변환할지 여부\n",
    "# include_length: 문장의 단어 수 데이터를 포함할지 여부\n",
    "# batch_first: 미니 배치 차원을 선두에 제공할지 여부\n",
    "# fix_length: 전체 문장을 지정한 길이가 되도록 padding\n",
    "# init_token, eos_token, pad_token, unk_token : 문장 선두, 문장 말미, padding, 미지어에 어떠한 단어를 부여하는 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f89857b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchtext.data' has no attribute 'TabularDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data 폴더에서 각 tsv파일을 읽는다.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# BERT용으로 처리하므로 10분 정도 시간이 걸린다.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_val_ds, test_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTabularDataset\u001b[49m\u001b[38;5;241m.\u001b[39msplits(\n\u001b[1;32m      4\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMDb_train.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     test \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIMDb_test.tsv\u001b[39m\u001b[38;5;124m'\u001b[39m, foramt \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     fields\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m, TEXT), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m,LABEL)])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# torchtext.data.Dataset의 split함수로 훈련 데이터와 검증 데이터를 나눈다.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m train_ds, val_ds \u001b[38;5;241m=\u001b[39m train_val_ds\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m     10\u001b[0m     split_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1234\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'TabularDataset'"
     ]
    }
   ],
   "source": [
    "# data 폴더에서 각 tsv파일을 읽는다.\n",
    "# BERT용으로 처리하므로 10분 정도 시간이 걸린다.\n",
    "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path = './data/', train='IMDb_train.tsv',\n",
    "    test ='IMDb_test.tsv', foramt ='tsv',\n",
    "    fields=[('Text', TEXT), ('Label',LABEL)])\n",
    "\n",
    "# torchtext.data.Dataset의 split함수로 훈련 데이터와 검증 데이터를 나눈다.\n",
    "train_ds, val_ds = train_val_ds.split(\n",
    "    split_ratio=0.8, random_state=random.seed(1234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT는 BERT가 가진 모든 단어로 BertEmbedding모듈을 작성하여 vocabulary는 전체 단어를 사용한다.\n",
    "# 훈련 데이터로 vocabulary를 만들지 않는다.\n",
    "\n",
    "# 우선 BERT용의 단어 사전을 사전형 변수에 준비한다.\n",
    "from utils.bert import BertTokenizer, load_vocab\n",
    "\n",
    "vocab_bert, ids_to_tokens_bert = load_vocab(\n",
    "    vocab_file = './vocab/bert-base-uncased-vocab.txt')\n",
    "\n",
    "# TEXT.vocab.stoi = vocab_bert(stoi는 string_to_ID로 단어에서 ID로 사전)로 하고 싶지만 \n",
    "# build_vocab를 실행하지 않으면 텍스트 오브젝트가 vocab의 멤버 변수를 갖지 않는다.\n",
    "# ('Field' object has no attribute 'vocab' 오류 발생)\n",
    "\n",
    "# 적당히 build_vocab에서 vocabulary를 작성하고 BERT의 vocabulary를 덮어 쓴다.\n",
    "TEXT.build_vocab(train_ds, min_freq=1)\n",
    "TEXT.vocab.stoi = vocab_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 작성(torchtext에서 iterator라고 불린다)\n",
    "batch_size = 32 # BERT에서는 16, 32 근처를 사용\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)\n",
    "\n",
    "val_ds = torchtext.data.Iterator(\n",
    "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "test_ds = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "# 사전 객체로 정리\n",
    "dataloaders_dict = {'train':train_dl, 'val':val_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동작 확인 검증 데이터셋으로 확인\n",
    "batch = next(iter(val_dl))\n",
    "print(batch.Text)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4abb3",
   "metadata": {},
   "source": [
    "## 8.4.2 감정 분석용 BERT 모델 구축\n",
    "- BERT모델에 대해 학습된 파라미터를 읽어들이고 긍정적인지 부정적인지 분류하는 어댑터 모듈을 설치하여 감정 분석을 하는 BERT 모델을 구축합니다.\n",
    "- BERT의 기본 모델을 구축한 후 학습된 파라미터를 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707cc3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\n",
      "bert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\n",
      "bert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\n",
      "bert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\n",
      "bert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\n",
      "bert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\n",
      "bert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\n",
      "bert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\n",
      "bert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\n",
      "bert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\n",
      "bert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\n",
      "bert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\n",
      "bert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\n",
      "bert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\n",
      "bert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\n",
      "bert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\n",
      "bert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\n",
      "bert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\n",
      "bert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\n",
      "bert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\n",
      "bert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\n",
      "bert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\n",
      "bert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\n",
      "bert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\n",
      "bert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\n",
      "bert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\n",
      "bert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\n",
      "bert.pooler.dense.weight→pooler.dense.weight\n",
      "bert.pooler.dense.bias→pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "from utils.bert import get_config, BertModel, set_learned_params\n",
    "\n",
    "# 모델 설정 JSON파일을 오브젝트 변수로 가져온다\n",
    "config = get_config(file_path='./weights/bert_config.json')\n",
    "\n",
    "# BERT 모델 작성\n",
    "net_bert = BertModel(config)\n",
    "\n",
    "# BERT 모델에 학습된 파라미터 설정\n",
    "net_bert = set_learned_params(\n",
    "    net_bert, weights_path='./weights/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ae47d",
   "metadata": {},
   "source": [
    "- BERT의 기본 모델에 문장 분류를 위한 어댑터로 전결합 층을 하나만 연결한 BertForIMDb 클래스 생성\n",
    "- BERT는 클래스 분류 시 문장 첫 번째 단어 [CLS]의 특징량을 입력한 텍스트 데이터의 특징량을 사용합니다.\n",
    "- BERT는 선두 단어의 특징량을 사용하여 Next Sentence Prediction을 사전 학습 작업으로 실행. BERT에서 입력 문장의 의미를 알 수 있는(적어도 입력된 두 문장의 의미가 연결되었는지 판단이 설 정도의 정보를 보유하는)것 처럼 선두 단어의 특징량을 만드는 방법이 사전 학습되었으며 선두 단어의 특징량이 입력 문장 전체의 특징을 반영합니다. 반면에 Transformer는 사전 작업이 없습니다.\n",
    "- 문장 분류에 선두 단어를 사용하여 역전파로 선두 단어의 특징량이 텍스트 데이터의 특징을 나타내도록 학습. BERT는 선두 단어가 입력 테스트 전체의 특징을 가지도록 사전 작업에서 결합 파라미터가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f354c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BertForIMDb(nn.Module):\n",
    "    '''BERT 모델에 IMDb 내용이 긍정적/부정적인지 판정하는 부분을 연결한 모델'''\n",
    "    \n",
    "    def __init__(self, net_bert):\n",
    "        super(BertForIMDb, self).__init__()\n",
    "        \n",
    "        # BERT 모듈\n",
    "        self.bert = net_bert # BERT 모델\n",
    "        \n",
    "        # head에 긍정적/부정적 예측 추가\n",
    "        # 입력은 BERT의 출력 특징량의 차원, 출력은 긍정적/부정적 두 가지\n",
    "        self.cls = nn.Linear(in_features=768, out_features=2)\n",
    "        \n",
    "        # 가중치 초기화 처리\n",
    "        nn.init.normal_(self.cls.weight, std=0.02)\n",
    "        nn.init.normal_(self.cls.bias, 0)\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=False, attention_show_fig=False):\n",
    "        '''\n",
    "        input_ids: [batch_size, sequence_length] 문장의 단어 ID 나열\n",
    "        token_type_ids: [batch_size, sequence_length] 각 단어가 첫 번째 문장인지 두 번째 문장인지 나타내는 id\n",
    "        attention_mask: Transformer의 마스크와 같은 기능의 마스킹\n",
    "        output_all_encoded_layers: 반환 값을 전체 TransformerBlock 모듈의 출력으로 할 것인지 마지막 층만 한정할지의 플래그\n",
    "        attention_show_fig: Self-Attention의 가중치를 반환할지의 플래그\n",
    "        '''\n",
    "        \n",
    "        # BERT의 기본 모델 부분의 순전파\n",
    "        # 순전파한다.\n",
    "        if attention_show_fig == True:\n",
    "            '''attention_show의 경우 attention_probs도 반환'''\n",
    "            encoded_layers, pooled_output, attention_probs = self.bert(\n",
    "                input_ids, token_type_ids, attention_mask,\n",
    "                output_all_encoded_layers, attention_show_fig)\n",
    "        elif attention_show_fig == False:\n",
    "            encoded_layers, pooled_output = self.bert(\n",
    "                input_ids, token_type_ids, attention_mask,\n",
    "                output_all_encoded_layers, attention_show_fig)\n",
    "            \n",
    "        # 입력 문장의 첫 단어 [CLS]의 특징량을 사용하여 긍정적/부정적인지 분류\n",
    "        vec_0 = encoded_layers[:, 0, :]\n",
    "        vec_0 = vec_0.view(-1, 768) # size를 (batch_size, hidden_size)로 변환\n",
    "        out = self.cls(vec_0)\n",
    "        \n",
    "        # attention_show의 경우 attention_probs(마지막)도 반환\n",
    "        if attention_show_fig == True:\n",
    "            return out, attention_probs\n",
    "        elif attention_show_fig == False:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f87beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 구축\n",
    "net = BertForIMDb(net_bert)\n",
    "\n",
    "# 훈련 모드로 설정\n",
    "net.train()\n",
    "\n",
    "print('네트워크 설정 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09e835",
   "metadata": {},
   "source": [
    "## 8.4.3 BERT의 파인튜닝을 위한 설정\n",
    "- BERT관련 논문에서는 12단 BertLayer의 모든 파라미터를 튜닝합니다.\n",
    "- 12단 모두 파인튜닝하기에는 많은 시간이 필요(+ GPU 메모리를 많이 차지하여 미니 배치 크기를 32에서 16으로 해야함)\n",
    "- 학습 시간을 단축하기 위하여 마지막 12단의 BertLayer만 파인 튜닝하여 1~11단의 BertLayer 파라미터는 변경하지 않도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b56311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 계산을 마지막 BertLayer 모듈과 추가한 분류 어댑터만 실행\n",
    "\n",
    "# 1. 먼저 모두 기울기 계산 False로 한다.\n",
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. 마지막 BertLayer 모듈을 기울기 계산하도록 변경\n",
    "for name, param in net.bert.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. 식별기를 기울기 계산을 하도록 변경\n",
    "for name, param in net.cls.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b951301",
   "metadata": {},
   "source": [
    "- 계속하여 최적화 기법과 손실함수 정의. 최적화 설정은 BERT 논문에서 권장된 파라미터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5daf739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 기법 설정\n",
    "\n",
    "# BERT의 원래 부분을 파인튜닝\n",
    "optimizer = optim.Adam([\n",
    "    {'params':net.bert.encoder.layer[-1].parameters(), 'lr':5e-5},\n",
    "    {'params':net.cls.parameters(), 'lr':5e-5}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "# 손실함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()를 계산한 후 nn.NLLoss(negative log likelihood loss) 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46376d1",
   "metadata": {},
   "source": [
    "## 8.4.4 학습 및 검증 실시\n",
    "- BertForIMDb의 학습 및 검증을 실행.\n",
    "- 이번 절에서는 [PAD]에 대해 Self-Attention을 적용하지 않도록 하는 attention_mask를 생략하여 None으로 진행\n",
    "- 사전 학습으로 [PAD]가 의미 없음을 배웠고 이번 절 내용은 [PAD]에 대한 attention_mask를 생략해도 성능에는 거의 변함이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a8a569",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net\n\u001b[1;32m     87\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 88\u001b[0m net_trained \u001b[38;5;241m=\u001b[39m train_model(net, \u001b[43mdataloaders_dict\u001b[49m, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloaders_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#모델을 학습시키는 함수 작성\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    # GPU를 사용할 수 있는지 확인\n",
    "    device = torch.deivce('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('사용장치:', device)\n",
    "    print('----start----')\n",
    "    \n",
    "    # 네트워크를 GPU로\n",
    "    net.to(device)\n",
    "    \n",
    "    # 네트워크가 어느 정도 고정되면 고속화시킨다.\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # 미니 배치 크기\n",
    "    batch_size = dataloaders_dict['train'].batch_size\n",
    "    \n",
    "    # 에폭 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        # 에폭별 훈련 및 검증 루프\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                net.train() # 모델을 훈련 모드로\n",
    "            else:\n",
    "                net.eval()  # 모델을 검증 모드로\n",
    "                \n",
    "            epoch_loss = 0.0 # 에폭의 손실 합\n",
    "            epoch_corrects = 0 # 에폭의 정답 수\n",
    "            iteration = 1\n",
    "            \n",
    "            # 개시 시간 저장\n",
    "            t_epoch_start = time.time()\n",
    "            t_iter_start = time.time()\n",
    "            \n",
    "            # 데이터 로더에서 미니 배치를 꺼내는 루프\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batch는 텍스트와 라벨의 사전형 변수\n",
    "                \n",
    "                # GPU를 사용할 수 있다면 GPU로 데이터를 보낸다\n",
    "                inputs = batch.Text[0].to(device) # 문장\n",
    "                labels = batch.Label.to(device)  # 라벨\n",
    "                \n",
    "                # 옵티마이저 초기화\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 순전파 계산\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    \n",
    "                    # BertForIMDb에 입력\n",
    "                    outputs = net(inputs, token_type_ids=None, attention_mask=None,\n",
    "                                  output_all_encoded_layers=False, attention_show_fig=False)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels) # 손실 계산\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1) # 라벨 예측\n",
    "                    \n",
    "                    # 훈련 시에는 역전파\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0): # 10iter에 한 번 손실을 표시\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            acc = (torch.sum(preds == labels.data)\n",
    "                                  ).double()/batch_size\n",
    "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec. || 이 반복의 정답률: {}'.format(\n",
    "                                    iteration, loss.item(), duration, acc))\n",
    "                            t_iter_start = time.time()\n",
    "                            \n",
    "                    iteration += 1\n",
    "                    \n",
    "                    # 손실과 정답 수의 합계 갱신\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            # 에폭별 손실과 정답률\n",
    "            t_epoch_finish = time.time()\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('Epoch {}/{} | {:^5} | Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "            t_epoch_start = time.time()\n",
    "            \n",
    "    return net\n",
    "\n",
    "num_epochs = 2\n",
    "net_trained = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c517936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 네트워크 파라미터 저장\n",
    "save_path = './weights/bert_fine_tuning_IMDb.pth'\n",
    "torch.save(net_trained.state_dict(), save_path)\n",
    "\n",
    "# 테스트 데이터의 정답률을 구한다.\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "net_trained.eval() # 모델을 검증 모드로\n",
    "net_trained.to(device)\n",
    "\n",
    "# 에폭의 정답 수를 기록하는 변수\n",
    "epoch_corrects = 0\n",
    "\n",
    "for batch in tqdm(test_dl): # 테스트 데이터의 데이터 로더\n",
    "    # batch는 텍스트와 라벨의 사전 오브젝트\n",
    "    # GPU를 사용할 수 있다면 GPU로 데이터를 보낸다.\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    inputs = batch['Text'][0].to(device) # 문장\n",
    "    labels = batch.Label.to(device)      # 라벨\n",
    "    \n",
    "    # 순전파 계산\n",
    "    with torch.set_grad_enabled(False):\n",
    "        \n",
    "        # BertForIMDb에 입력\n",
    "        outputs = net_trained(inputs, token_type_ids=None, attention_mask=None,\n",
    "                              output_all_encoded_layers=False, attention_show_fig=False)\n",
    "        \n",
    "        loss = criterion(outputs, labels) # 손실 계산\n",
    "        _, preds = torch.max(outputs, 1) # 라벨 예측\n",
    "        epoch_corrects += torch.sum(preds == labels.data) # 정답 수의 합계 갱신\n",
    "        \n",
    "# 정답률\n",
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "\n",
    "print('테스트 데이터 {}개에서 정답률 : {:.4f}'.format(len(test_dl.dataset), epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdbc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8dd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63e6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d02849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
