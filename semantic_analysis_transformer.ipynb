{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d787375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsv 형식의 파일\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import string\n",
    "\n",
    "# 훈련 데이터의 tsv 파일 작성\n",
    "f = open('./data/text_train.tsv', 'w')\n",
    "\n",
    "path ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d77ad8",
   "metadata": {},
   "source": [
    "전처리 및 단어 분할 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf303b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구두점 문자: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['I', 'like', 'cats', '.']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "# 다음 기호는 스페이스(공백)로 치환(쉼표, 마침표 제외)\n",
    "# punctuation은 구두점\n",
    "print(\"구두점 문자:\", string.punctuation)\n",
    "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "\n",
    "# 전처리\n",
    "def preprocessing_text(text):\n",
    "    # 개행 코드 삭제\n",
    "    text = re.sub('<br />', '', text)\n",
    "    \n",
    "    # 쉼표, 마침표 이외의 기호를 공백으로 치환\n",
    "    for p in string.punctuation:\n",
    "        if (p == '.') or (p == ','):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, ' ')\n",
    "    \n",
    "    # 쉼표, 마침표의 전후에 공백 추가\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace(',', ' , ')\n",
    "    return text\n",
    "\n",
    "# 띄어쓰기(이번에는 영어 데이터 이며 임시로 공백으로 구분)\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split()\n",
    "\n",
    "# 전처리 및 띄어쓰기를 포함한 함수 정의\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret\n",
    "\n",
    "print(tokenizer_with_preprocessing('I like cats.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c166a",
   "metadata": {},
   "source": [
    "Transformer 구현(분류 작업용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedder 모듈\n",
    "import torch.nn as nn\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    '''id로 표시된 단어를 벡터로 변환'''\n",
    "    \n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings=text_embedding_vectors, freeze=True)\n",
    "        # freeze=True에 의해 역전파로 갱신되지 않고 변하지 않는다\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "        \n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d12c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797e4aa7",
   "metadata": {},
   "source": [
    "훈련 및 검증 함수의 구현과 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    # GPU 사용 확인\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('사용장치: ', device)\n",
    "    print('-----start-----')\n",
    "    \n",
    "    # 네트워크를 MPS로\n",
    "    net.to(device)\n",
    "    \n",
    "    # 네트워크가 어느 정도 고정되면 고속화 시킨다\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # 에폭 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        # 에폭별 훈련 및 검증 루프\n",
    "        for phase in ['train','val']:\n",
    "            if phase == 'train':\n",
    "                net.train() # 모델을 훈련 모드로\n",
    "            else:\n",
    "                net.eval() # 모델을 검증 모드로\n",
    "            epoch_loss = 0.0 # 에폭 손실의 합\n",
    "            epoch_corrects = 0 # 에폭의 정답 수\n",
    "            \n",
    "            # 데이터 로더에서 미니 배치를 꺼내는 루프\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # 배치는 텍스트와 라벨의 사전 오브젝트\n",
    "                \n",
    "                # GPU를 사용할 수 있으면 GPU로 데이터를 보낸다\n",
    "                inputs = batch.Text[0].to(device)\n",
    "                labels = batch.Label.to(device)\n",
    "                \n",
    "                # 옵티마이저 초기화\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 순전파 계산\n",
    "                # False 시(추론 모드) 역전파나 가중치 업데이트가 일어나지 않음\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                     \n",
    "                    # 마스크 작성\n",
    "                    input_pad = 1 # 단어 ID에 있어서 '<pad>': 1 이므로\n",
    "                    input_mask = (inputs != input_pad)\n",
    "                    \n",
    "                    # Transformer에 입력\n",
    "                    outputs, _, _ = net(inputs, input_mask)\n",
    "                    loss = criterion(outputs, labels) # 손실 계산\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1) # 라벨 예측\n",
    "                    \n",
    "                    # 훈련 시에는 역전파\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    # 결과 계산\n",
    "                    epoch_loss += loss.item() * inputs.size(0) # 손실 합계 갱신\n",
    "                    # 정답 수 합계를 갱신\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "                # 에폭별 손실과 정답률\n",
    "                epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "                epoch_acc = epoch_corrects.double(\n",
    "                ) / len(dataloaders_dict[phase].dataset)\n",
    "                \n",
    "                print('Epoch {}/{} | {:^5} | Loss: {:.4f} Acc: {:.4f}'.\n",
    "                     format(epoch+1, num_epochs, phase, epoch_loss, epoch_acc))\n",
    "                \n",
    "            return net\n",
    "        \n",
    "# 손실 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax() 를 계산한 뒤 nn.NLLLoss(negative log likelihood loss) 계산\n",
    "\n",
    "# 최적화 기법 설정\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 및 검증 실행\n",
    "num_epochs = 10\n",
    "net_trained = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a367e4e",
   "metadata": {},
   "source": [
    "테스트 데이터에서의 추론과 판정 근거의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "net_trained.eval() # 모델을 검증 모드로\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0 # 에폭의 정답 수\n",
    "\n",
    "for batch in (test_dl): # 테스트 데이터의 데이터 로더\n",
    "    # 배치는 텍스트와 라벨의 사전 오브젝트\n",
    "    \n",
    "    # MPS를 사용할 수 있다면 MPS로 데이터를 보낸다\n",
    "    inputs = batch.Text[0].to(device)\n",
    "    labels = batch.Label.to(device)\n",
    "    \n",
    "    # 순전파 계산\n",
    "    with torch.set_grad_enabled(False):\n",
    "        \n",
    "        # 마스크 작성\n",
    "        input_pad = 1 # 단어 ID에 있어서 '<pad>':1 이므로\n",
    "        input_mask = (inputs != input_pad)\n",
    "        \n",
    "        # Transformer에 입력\n",
    "        outputs, _, _ = net_trained(inputs, input_mask)\n",
    "        _, preds = torch.max(outputs, 1) # 라벨 예측\n",
    "        \n",
    "        # 결과 계산\n",
    "        # 정답 수 합계 갱신\n",
    "        epoch_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "# 정답률\n",
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "\n",
    "print('테스트 데이터 {}개의 정답률: {:.4f}'.format(len(test_dl.dataset), epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576d3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e309f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f9e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd846f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf963b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
